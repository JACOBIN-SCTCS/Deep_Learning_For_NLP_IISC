{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import jsonlines\n",
    "import json\n",
    "import re\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_packed_sequence,pack_padded_sequence,pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import fasttext\n",
    "from torch.utils.data import SubsetRandomSampler,DataLoader,Subset\n",
    "from torchtext.vocab import GloVe\n",
    "from tqdm import tqdm\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "EMBED_DIM = 300\n",
    "HIDDEN_DIM = 128\n",
    "CNN_DIM = 256\n",
    "\n",
    "PATIENCE_PARAMETER = 4\n",
    "VALIDATION_LOSS_COMPUTE_STEP = 1\n",
    "\n",
    "\n",
    "NUM_FILTERS = 50\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "device_fast = torch.device('cpu')\n",
    "\n",
    "if torch.has_mps:\n",
    "    device_fast = torch.device('mps')\n",
    "elif torch.has_cuda:\n",
    "    device_fast = torch.device('cuda')\n",
    "\n",
    "#torch.manual_seed(0)\n",
    "#np.random.seed(0)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "glove = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#punctuation_words = open('punct.txt','w')\n",
    "#punct_in_file = set()\n",
    "#final_words = open('words.txt','w')\n",
    "#punctuations = set(list(string.punctuation))\n",
    "#vocab_words = set()\n",
    "\n",
    "def preprocess_text(text):\n",
    "        \n",
    "    text = re.sub(r'<br /><br />',\".\",text)\n",
    "    text = BeautifulSoup(text,'lxml').get_text().strip()\n",
    "    text = text.lower()\n",
    "\n",
    "    #text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = ' '.join(re.findall(r\"[\\w']+|[.,!;/\\\"]\", text))\n",
    "    \n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word == '':\n",
    "            continue\n",
    "        new_text.append(word)\n",
    "        #if '.' in word and len(word)>1:\n",
    "            #if 'http' in word:\n",
    "            #    words = word.split('.')\n",
    "            #    words[1] = ''.join(words[1:])\n",
    "            #    words = [words[0],words[1]]\n",
    "            #else:\n",
    "            #    words = word.split('.')\n",
    "           \n",
    "        #    words = word.split('.')\n",
    "        #    for w in words:\n",
    "        #        new_text.append(w)\n",
    "        #else:\n",
    "    \n",
    "    text = ' '.join(new_text)\n",
    "    words = nlp(text)\n",
    "    text =  \" \".join([token.text for token in words if not token.is_punct or token.text=='/' or token.text==\"\\\"\" or token.text==\".\"]).strip()\n",
    "    #review =  \" \".join([re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', token.text, flags=re.MULTILINE) for token in words])\n",
    "    #review  = \" \".join(new_text)\n",
    "    new_words = []\n",
    "    for word in text.split(\" \"):\n",
    "        \n",
    "        #vocab_words.add(word)\n",
    "        if word == 'n\\'t':\n",
    "            if len(new_words) > 1:\n",
    "                new_words[-1] = new_words[-1] + word\n",
    "            else:\n",
    "                new_words.append(word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    text = \" \".join(new_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = []\n",
    "train_dataset_labels = []\n",
    "#with open('./train.jsonl',encoding='utf-8') as f:\n",
    "with open('processed_dataset.jsonl',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        sample = json.loads(line)\n",
    "        train_dataset_labels.append(sample['label'])\n",
    "        preprocessed_dataset.append(sample)\n",
    "train_dataset_labels = np.array(train_dataset_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordEmbeddingforText(text,glove=glove):\n",
    "    \n",
    "    length = 0\n",
    "    words = []\n",
    "    text = text.strip()\n",
    "    for word in text.split(' '):\n",
    "        length+=1\n",
    "        word_embedding = glove[word]\n",
    "        words.append(word_embedding)\n",
    "\n",
    "    return torch.stack(words),length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_embed(review,glove=glove):\n",
    "    \n",
    "    sentences = review.split(\".\")\n",
    "    sentence_lengths = []\n",
    "    review_embeddings = []\n",
    "    num_sentences = 0\n",
    "    for sentence in sentences:\n",
    "        if sentence == '':\n",
    "            continue\n",
    "        s= sentence.strip()\n",
    "        num_sentences += 1\n",
    "        sentence_word_embeddings,sentence_length = getWordEmbeddingforText(s,glove)\n",
    "        sentence_lengths.append(sentence_length)\n",
    "        review_embeddings.append(sentence_word_embeddings)\n",
    "\n",
    "    return torch.nn.utils.rnn.pad_sequence(review_embeddings,batch_first=True),sentence_lengths,num_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self,reviews):\n",
    "        super().__init__()\n",
    "        self.reviews = reviews\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.reviews[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = []\n",
    "\n",
    "for review in preprocessed_dataset:\n",
    "    embeddings, sent_length ,n_sents = review_to_embed(review['text'])\n",
    "    processed_dataset.append({'review': embeddings,'sent_lengths': sent_length,'n_sent' : n_sents,'label' : review['label']})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReviewDataSet(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(batch_data):\n",
    " \n",
    "    \n",
    "    inputs = [b['review'] for b in batch_data]\n",
    "    sent_lengths = [ b['sent_lengths'] for b in batch_data ]\n",
    "    n_sentences = [ b['n_sent'] for b in batch_data ]\n",
    "    \n",
    "    labels = torch.tensor([b['label'] for b in batch_data])\n",
    "\n",
    "    labels = labels.unsqueeze(1)\n",
    "    \n",
    "    max_n_sentences = max([i.shape[0] for i in inputs] )\n",
    "    max_n_words = max([i.shape[1] for i in inputs])\n",
    "\n",
    " \n",
    "    processed_inputs = []\n",
    "    for inp in inputs:\n",
    "\n",
    "        t1 = torch.permute(inp,(2,1,0))\n",
    "        t1 = torch.nn.functional.pad(t1,(0,max_n_sentences-inp.shape[0],0,max_n_words-inp.shape[1]))\n",
    "        t1 = torch.permute(t1,(2,1,0))\n",
    "        processed_inputs.append(t1)\n",
    "\n",
    "    final_inp = torch.stack(processed_inputs)\n",
    "    #inputs = pad_sequence(inputs,batch_first=True)\n",
    "    return  {'input' : final_inp , 'sent_lengths': sent_lengths , 'n_sent' : n_sentences ,'labels' : labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx,valid_idx = train_test_split(np.arange(train_dataset_labels.shape[0]), \n",
    "    test_size=0.2,\n",
    "    shuffle= True,\n",
    "    stratify= train_dataset_labels,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_dataloader = DataLoader(dataset,16,sampler=train_sampler,collate_fn=collate_function)\n",
    "valid_dataloader = DataLoader(dataset,16,sampler=valid_sampler,collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 128])\n",
      "torch.Size([16, 37, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5194],\n",
       "        [0.5044],\n",
       "        [0.5109],\n",
       "        [0.5171],\n",
       "        [0.5095],\n",
       "        [0.5025],\n",
       "        [0.5209],\n",
       "        [0.5212],\n",
       "        [0.5171],\n",
       "        [0.5137],\n",
       "        [0.5254],\n",
       "        [0.5183],\n",
       "        [0.4990],\n",
       "        [0.5246],\n",
       "        [0.5116],\n",
       "        [0.5147]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class EnsembleModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,EMBED_DIM,CNN_DIM,HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_size = CNN_DIM,hidden_size = HIDDEN_DIM, batch_first = True)\n",
    "        self.cnn = nn.Conv1d(in_channels=EMBED_DIM,out_channels=CNN_DIM,kernel_size=3)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM,1)\n",
    "\n",
    "\n",
    "    def forward(self,inp : torch.Tensor,n_sents=None):\n",
    "\n",
    "        ## inp  = (batch_size,max_sent_length,max_word_length,embed_dim)\n",
    "\n",
    "        outputs = []\n",
    "      \n",
    "        \n",
    "        for i in range(inp.shape[1]):\n",
    "            current_inp = inp[:,i,:,:]\n",
    "            current_inp = torch.permute(current_inp,(0,2,1))\n",
    "            current_output = self.cnn(current_inp)\n",
    "            current_output = F.max_pool1d(current_output,kernel_size = current_output.shape[2]).squeeze(dim=2)\n",
    "            outputs.append(current_output)\n",
    "        \n",
    "        #print(len(outputs))\n",
    "        #print(outputs[0].shape)\n",
    "        lstm_in = torch.stack(outputs,dim=1)\n",
    "   \n",
    "        packed_input = pack_padded_sequence(lstm_in,n_sents,batch_first=True,enforce_sorted=False)\n",
    "        packed_output,hidden = self.rnn(packed_input)\n",
    "        output,output_lengths = pad_packed_sequence(packed_output,batch_first=True)\n",
    "\n",
    "        hidden = torch.permute(hidden,(1,0,2))\n",
    "        hidden = hidden.contiguous().view((hidden.shape[0],-1))\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return nn.Sigmoid()(out)\n",
    "        #out = self.cnn(inp)\n",
    "        #return out\n",
    "\n",
    "batch_data = next(iter(train_dataloader))\n",
    "j = EnsembleModel(EMBED_DIM,CNN_DIM,HIDDEN_DIM)\n",
    "j(batch_data['input'],batch_data['n_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class CNNLSTMAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,EMBED_DIM,CNN_DIM,HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_size = CNN_DIM,hidden_size = HIDDEN_DIM, batch_first = True)\n",
    "        self.cnn = nn.Conv1d(in_channels=EMBED_DIM,out_channels=CNN_DIM,kernel_size=3)\n",
    "        self.attention_layer = nn.Linear(HIDDEN_DIM,1)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM,HIDDEN_DIM)\n",
    "        self.out_fc = nn.Linear(HIDDEN_DIM,1)\n",
    "        self.batchnorm1d = nn.BatchNorm1d(CNN_DIM)\n",
    "    def forward(self,inp : torch.Tensor,n_sents=None):\n",
    "\n",
    "        ## inp  = (batch_size,max_sent_length,max_word_length,embed_dim)\n",
    "\n",
    "        outputs = []\n",
    "      \n",
    "        \n",
    "        for i in range(inp.shape[1]):\n",
    "            current_inp = inp[:,i,:,:]\n",
    "            current_inp = torch.permute(current_inp,(0,2,1))\n",
    "            current_output = self.cnn(current_inp)\n",
    "            current_output = F.max_pool1d(current_output,kernel_size = current_output.shape[2]).squeeze(dim=2)\n",
    "            outputs.append(current_output)\n",
    "        \n",
    "        #print(len(outputs))\n",
    "        #print(outputs[0].shape)\n",
    "        lstm_in = torch.stack(outputs,dim=2)\n",
    "        lstm_in = self.batchnorm1d(lstm_in)\n",
    "        lstm_in = torch.permute(lstm_in,(0,2,1))\n",
    "\n",
    "        packed_input = pack_padded_sequence(lstm_in,n_sents,batch_first=True,enforce_sorted=False)\n",
    "        packed_output,hidden = self.rnn(packed_input)\n",
    "        output,output_lengths = pad_packed_sequence(packed_output,batch_first=True)\n",
    "        attention_logs = self.attention_layer(output).squeeze(dim=2)\n",
    "        attention_score = F.softmax(attention_logs,dim=1).unsqueeze(2)\n",
    "\n",
    "        final_out = attention_score*output\n",
    "\n",
    "        averaged_vector = torch.sum(final_out,dim=1,keepdim=False)\n",
    "\n",
    "        #hidden = torch.permute(hidden,(1,0,2))\n",
    "        #hidden = hidden.contiguous().view((hidden.shape[0],-1))\n",
    "        out = F.leaky_relu(self.fc(averaged_vector))\n",
    "        out = self.out_fc(out)\n",
    "        return nn.Sigmoid()(out)\n",
    "        #out = self.cnn(inp)\n",
    "        #return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import  datetime\n",
    "\n",
    "def train(model,train_dataloader,valid_dataloader,num_epochs,criterion,optimizer,\n",
    "    checkpoint_name='best_model.pt',\n",
    "    device_train = device_fast,use_rnn = False,log=True):\n",
    "\n",
    "    tensorboard_name='Ensemble'\n",
    "    if log == True:\n",
    "        current_datetime = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "        tensorboard_name = tensorboard_name + \"_\" + current_datetime\n",
    "        writer = SummaryWriter('runs/' + tensorboard_name)\n",
    "    \n",
    "    \n",
    "    model = model.to(device_train)\n",
    "    clip = 0\n",
    "    if use_rnn:\n",
    "        clip = 5\n",
    "\n",
    "    best_validation_loss = 1000.0\n",
    "    valdiation_loss_not_decreased_steps = 0\n",
    "    \n",
    "    model.train()\n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        training_set_size = 0\n",
    "        training_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for data in tqdm(train_dataloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            input_reviews,sent_lengths,n_sents,output_labels = data['input'], data['sent_lengths'],data['n_sent'],data['labels']\n",
    "            input_reviews = input_reviews.to(device_train)\n",
    "            training_set_size += input_reviews.shape[0]\n",
    "            output = model(input_reviews,n_sents)\n",
    "            output = output.to(device_cpu)\n",
    "            loss = criterion(output,output_labels.float())\n",
    "            training_loss += loss.item()\n",
    "            loss.backward()\n",
    "            if use_rnn:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "            optimizer.step()\n",
    "        \n",
    "        current_training_loss = training_loss\n",
    "        if log==True:\n",
    "            print(\"Epoch \" + str(e) + \" Average Training Loss = \" +  str(current_training_loss))\n",
    "            writer.add_scalars(tensorboard_name + 'Training Loss vs Epoch',{'train' : current_training_loss},e)\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        if valid_dataloader is None:\n",
    "            continue\n",
    "        \n",
    "        validation_set_size  = 0 \n",
    "        if e% VALIDATION_LOSS_COMPUTE_STEP==0:\n",
    "            correct_count = 0\n",
    "            validation_loss = 0\n",
    "\n",
    "            for i,data in enumerate(valid_dataloader,0):\n",
    "                input_reviews,sent_lengths,n_sents,output_labels = data['input'], data['sent_lengths'],data['n_sent'],data['labels']\n",
    "                input_reviews = input_reviews.to(device_train)\n",
    "                validation_set_size += input_reviews.shape[0]\n",
    "                output = model(input_reviews,n_sents)\n",
    "                output = output.to(device_cpu)\n",
    "                loss = criterion(output,output_labels.float())\n",
    "                validation_loss += loss.item()\n",
    "                nearest_class = torch.round(output)\n",
    "\n",
    "                correct = (nearest_class == output_labels.float()).float()\n",
    "                correct_count += correct.sum()\n",
    "            correct_count = int(correct_count)\n",
    "            current_validation_accuracy = (correct_count/validation_set_size)*100\n",
    "            current_validation_loss = (1.0* validation_loss)\n",
    "            if log == True:\n",
    "                print(\"Epoch \" + str(e) + \" \" +  \"Validation Loss = \" + str(current_validation_loss) )\n",
    "                print(\"Validation Set Accuracy = \" + str((correct_count/validation_set_size)*100) )\n",
    "                writer.add_scalar(tensorboard_name + ' Validation Accuracy vs Epoch ',(correct_count/validation_set_size*100),e)\n",
    "                writer.add_scalars('Validation Loss vs Epoch',{'valid' : current_validation_loss},e)\n",
    "\n",
    "            \n",
    "            if log==True:\n",
    "                if current_validation_loss < best_validation_loss:\n",
    "                    valdiation_loss_not_decreased_steps = 0\n",
    "                    torch.save(model.state_dict(),checkpoint_name)\n",
    "                    best_validation_loss = current_validation_loss\n",
    "                else:\n",
    "                    valdiation_loss_not_decreased_steps +=1\n",
    "        if log == True:\n",
    "            if valdiation_loss_not_decreased_steps >= PATIENCE_PARAMETER:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:03<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Average Training Loss = 623.0562809258699\n",
      "Epoch 0 Validation Loss = 125.50198939070106\n",
      "Validation Set Accuracy = 89.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:48<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Training Loss = 445.4386263201013\n",
      "Epoch 1 Validation Loss = 121.80933324992657\n",
      "Validation Set Accuracy = 90.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:17<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Training Loss = 326.89077874831855\n",
      "Epoch 2 Validation Loss = 137.2986930590123\n",
      "Validation Set Accuracy = 87.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:28<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Training Loss = 221.8094484594185\n",
      "Epoch 3 Validation Loss = 146.21994547825307\n",
      "Validation Set Accuracy = 89.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:35<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Training Loss = 149.96648020023713\n",
      "Epoch 4 Validation Loss = 169.37581068719737\n",
      "Validation Set Accuracy = 89.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:18<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Training Loss = 115.21211249880434\n",
      "Epoch 5 Validation Loss = 172.99949749559164\n",
      "Validation Set Accuracy = 90.01249999999999\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "net = CNNLSTMAttention(EMBED_DIM,CNN_DIM,HIDDEN_DIM)\n",
    "train(net,train_dataloader,valid_dataloader,50,nn.BCELoss(),optim.Adam(net.parameters(),0.001),'cnn_rnn_att_adam_batch_nrom.pt',device_fast,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 56.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Average Training Loss = 249.89463835954666\n",
      "Epoch 0 Validation Loss = 57.24660049378872\n",
      "Validation Set Accuracy = 77.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 78.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Training Loss = 183.85778238624334\n",
      "Epoch 1 Validation Loss = 56.50982944667339\n",
      "Validation Set Accuracy = 77.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 79.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Training Loss = 112.18427886813879\n",
      "Epoch 2 Validation Loss = 66.03571812063456\n",
      "Validation Set Accuracy = 77.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 83.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Training Loss = 57.646459883544594\n",
      "Epoch 3 Validation Loss = 88.15489272028208\n",
      "Validation Set Accuracy = 76.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 78.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Training Loss = 33.90409373585135\n",
      "Epoch 4 Validation Loss = 86.20754048228264\n",
      "Validation Set Accuracy = 76.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 60.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Training Loss = 30.087093391630333\n",
      "Epoch 5 Validation Loss = 118.65928636491299\n",
      "Validation Set Accuracy = 76.7\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "net = EnsembleModel(EMBED_DIM,CNN_DIM,HIDDEN_DIM)\n",
    "train(net,train_dataloader,valid_dataloader,50,nn.BCELoss(),optim.Adam(net.parameters(),0.001),'cnn_rnn_dnn_adam.pt',device_fast,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_name,test_data,test_lengths,test_labels):\n",
    "    model = CNNLSTMAttention(EMBED_DIM,CNN_DIM,HIDDEN_DIM)\n",
    "    model.load_state_dict(torch.load(model_name,map_location=device_cpu))\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    for i in range(len(test_data)):\n",
    "        ans = model(test_data[i],[test_lengths[i]])\n",
    "        ans = torch.round(ans)\n",
    "        if ans[0][0] == test_labels[i]:\n",
    "            count+=1\n",
    "    \n",
    "    print(\"Accuracy = \" + str((count/len(test_data)*100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivitsu329\\Documents\\environments\\nlpenv\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_dataset_labels = []  \n",
    "test_processed_text = []\n",
    "with open(\"./E0334 Assignment2 Test Dataset.csv\",encoding='utf-8') as csvfile:\n",
    "    csvFile = csv.reader(csvfile)\n",
    "    next(csvFile)\n",
    "    for line in csvFile:\n",
    "        processed_text = preprocess_text(line[0])\n",
    "        label = 1.0 if line[1] == 'positive' else 0.0\n",
    "        test_dataset_labels.append(label)\n",
    "        test_processed_text.append(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word_embeddings = [] \n",
    "test_sentence_lengths = []\n",
    "\n",
    "for i in range(len(test_processed_text)):\n",
    "    \n",
    "    current_embeddings,current_sent_lengths,current_n_sent = review_to_embed(test_processed_text[i]) \n",
    "    test_word_embeddings.append(current_embeddings.clone().detach().unsqueeze(0))\n",
    "    test_sentence_lengths.append(current_n_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 43, 300])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence_lengths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence_lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90.13901390139014\n"
     ]
    }
   ],
   "source": [
    "test('./cnn_rnn_att_adam.pt',test_word_embeddings,test_sentence_lengths,test_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "random_prob = 0.5*torch.ones((64,1))\n",
    "true_labels = torch.bernoulli(random_prob)\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (rnn): GRU(256, 128, batch_first=True)\n",
       "  (cnn): Conv1d(300, 256, kernel_size=(3,), stride=(1,))\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "crit = nn.BCELoss()\n",
    "optimizer =optim.Adam(j.parameters(),lr = 0.01)\n",
    "j.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 77, 256])\n",
      "0.6655454635620117\n",
      "torch.Size([64, 77, 256])\n",
      "0.6645953059196472\n",
      "torch.Size([64, 77, 256])\n",
      "0.66114342212677\n",
      "torch.Size([64, 77, 256])\n",
      "0.6593537926673889\n",
      "torch.Size([64, 77, 256])\n",
      "0.6578088402748108\n",
      "torch.Size([64, 77, 256])\n",
      "0.6835843920707703\n",
      "torch.Size([64, 77, 256])\n",
      "0.6554070711135864\n",
      "torch.Size([64, 77, 256])\n",
      "0.6443350315093994\n",
      "torch.Size([64, 77, 256])\n",
      "0.6433554291725159\n",
      "torch.Size([64, 77, 256])\n",
      "0.7229409217834473\n",
      "torch.Size([64, 77, 256])\n",
      "0.6723809242248535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pred_out \u001b[39m=\u001b[39m j(batch_data[\u001b[39m'\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     loss \u001b[39m=\u001b[39m crit(pred_out,true_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/environments/gymenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb Cell 15\u001b[0m in \u001b[0;36mNetwork.forward\u001b[0;34m(self, inp, n_sents)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m current_inp \u001b[39m=\u001b[39m inp[:,i,:,:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m current_inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(current_inp,(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m current_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(current_inp)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m current_output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmax_pool1d(current_output,kernel_size \u001b[39m=\u001b[39m current_output\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/depressedcoder/DLNLP/Assignment3/sol.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m outputs\u001b[39m.\u001b[39mappend(current_output)\n",
      "File \u001b[0;32m~/environments/gymenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/environments/gymenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/environments/gymenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_out = j(batch_data['input'])\n",
    "    loss = crit(pred_out,true_labels)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 77, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4484],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4865],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4403],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4494],\n",
       "        [0.4491],\n",
       "        [0.0278],\n",
       "        [0.4491],\n",
       "        [0.4362],\n",
       "        [0.4490],\n",
       "        [0.4520],\n",
       "        [0.4361],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4494],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4503],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4513],\n",
       "        [0.4494],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4494],\n",
       "        [0.4486],\n",
       "        [0.4488],\n",
       "        [0.4361],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4494],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4494],\n",
       "        [0.4491],\n",
       "        [0.4485],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.4520],\n",
       "        [0.4491],\n",
       "        [0.4491],\n",
       "        [0.9746],\n",
       "        [0.4491],\n",
       "        [0.9837],\n",
       "        [0.4491],\n",
       "        [0.4491]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j(batch_data['input'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (27) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vivitsu329\\Documents\\GitHub\\Deep_Learning_For_NLP_IISC\\Assignment3\\sol.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vivitsu329/Documents/GitHub/Deep_Learning_For_NLP_IISC/Assignment3/sol.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m i1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m12\u001b[39m,\u001b[39m30\u001b[39m,\u001b[39m50\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vivitsu329/Documents/GitHub/Deep_Learning_For_NLP_IISC/Assignment3/sol.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m i2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m11\u001b[39m,\u001b[39m27\u001b[39m,\u001b[39m50\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vivitsu329/Documents/GitHub/Deep_Learning_For_NLP_IISC/Assignment3/sol.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m final_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mrnn\u001b[39m.\u001b[39;49mpad_sequence([i1,i2])\n",
      "File \u001b[1;32mc:\\Users\\Vivitsu329\\Documents\\environments\\nlpenv\\lib\\site-packages\\torch\\nn\\utils\\rnn.py:396\u001b[0m, in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    392\u001b[0m         sequences \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39munbind(\u001b[39m0\u001b[39m)\n\u001b[0;32m    394\u001b[0m \u001b[39m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[39m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mpad_sequence(sequences, batch_first, padding_value)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (27) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "pad = nn.ConstantPad2d(())\n",
    "i2 = torch.randn((11,27,50))\n",
    "\n",
    "\n",
    "final_out = torch.nn.utils.rnn.pad_sequence([i1,i2],batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2576, -1.4110, -3.0002,  1.0355,  1.4575],\n",
       "         [ 1.9863, -0.6973,  0.2124,  0.2277,  0.0504],\n",
       "         [-0.6911,  0.6065,  1.6002, -1.1386,  0.5833]],\n",
       "\n",
       "        [[-0.1150, -0.1750,  0.2525,  0.1081, -0.0693],\n",
       "         [ 0.3150,  0.8368, -0.0991, -0.0759, -0.4504],\n",
       "         [ 0.6217, -0.9792, -1.6855,  1.4562,  0.3847]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.randn((2,3,5))\n",
    "q = torch.permute(g,(2,0,1))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2576,  1.9863, -0.6911],\n",
       "         [-0.1150,  0.3150,  0.6217]],\n",
       "\n",
       "        [[-1.4110, -0.6973,  0.6065],\n",
       "         [-0.1750,  0.8368, -0.9792]],\n",
       "\n",
       "        [[-3.0002,  0.2124,  1.6002],\n",
       "         [ 0.2525, -0.0991, -1.6855]],\n",
       "\n",
       "        [[ 1.0355,  0.2277, -1.1386],\n",
       "         [ 0.1081, -0.0759,  1.4562]],\n",
       "\n",
       "        [[ 1.4575,  0.0504,  0.5833],\n",
       "         [-0.0693, -0.4504,  0.3847]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.nn.functional.pad(q,(0,3,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.permute(i,(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2576, -1.4110, -3.0002,  1.0355,  1.4575],\n",
       "         [ 1.9863, -0.6973,  0.2124,  0.2277,  0.0504],\n",
       "         [-0.6911,  0.6065,  1.6002, -1.1386,  0.5833],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1150, -0.1750,  0.2525,  0.1081, -0.0693],\n",
       "         [ 0.3150,  0.8368, -0.0991, -0.0759, -0.4504],\n",
       "         [ 0.6217, -0.9792, -1.6855,  1.4562,  0.3847],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.8514e-02, -8.9418e-01, -7.8548e-01,  3.5751e-01],\n",
       "         [-1.2053e+00, -8.1523e-01,  8.9067e-01, -1.4337e+00],\n",
       "         [ 8.9685e-01,  1.6162e+00,  3.1155e-01, -2.1370e-01]],\n",
       "\n",
       "        [[-1.1456e+00,  1.3498e+00,  4.8107e-01,  3.2546e-01],\n",
       "         [ 7.3913e-01, -5.7459e-01, -1.0138e+00,  1.2696e+00],\n",
       "         [-1.0810e+00, -2.3811e+00,  9.7491e-01, -2.0539e+00]],\n",
       "\n",
       "        [[-1.1427e+00, -2.8126e-02, -4.5579e-01,  1.4867e+00],\n",
       "         [-3.9454e-01, -5.1207e-01,  4.7273e-01,  2.9859e-01],\n",
       "         [-9.2391e-02,  1.0780e+00, -1.2114e+00,  2.4218e+00]],\n",
       "\n",
       "        [[-1.3947e-01,  4.9323e-01, -3.3063e-01,  4.8126e-01],\n",
       "         [ 6.0514e-02, -3.6486e-01,  1.6370e+00, -4.9131e-01],\n",
       "         [ 1.8614e-01,  8.1679e-01,  2.5825e-01, -1.1861e+00]],\n",
       "\n",
       "        [[ 9.3769e-01, -3.0563e-01,  9.5881e-01, -2.6005e+00],\n",
       "         [ 6.4705e-01, -8.1550e-01,  4.2356e-01,  6.0810e-01],\n",
       "         [-4.9011e-01,  3.7321e-01,  1.4586e+00, -5.9765e-01]],\n",
       "\n",
       "        [[ 1.0451e+00,  1.1214e-01, -3.8421e-01,  1.5730e+00],\n",
       "         [ 1.5107e+00, -2.2145e-01,  1.3614e+00, -1.8556e+00],\n",
       "         [-4.2082e-01, -6.0904e-02,  7.4758e-01, -9.8998e-02]],\n",
       "\n",
       "        [[ 3.0577e-01, -1.1190e+00, -9.2371e-02, -2.2143e+00],\n",
       "         [-3.8315e-01,  4.0328e-01,  1.5698e+00,  4.0657e-01],\n",
       "         [-1.5480e+00, -3.2895e-01,  1.5014e-01, -2.2311e+00]],\n",
       "\n",
       "        [[ 1.7818e+00,  6.6711e-01, -7.6424e-01, -3.1303e-01],\n",
       "         [-4.2536e-01, -1.3430e+00, -6.9771e-04, -8.2715e-01],\n",
       "         [-1.5329e+00,  4.7453e-02, -1.3115e-01, -3.5139e-01]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('nlpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db937d70f0b42a9864491ccec092d177c951bc6bfc86971ae63a9e250c306d60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
