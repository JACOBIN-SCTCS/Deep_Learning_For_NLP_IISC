{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler,DataLoader\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EMBED_DIM = 300 \n",
    "ENC_BIDIRECTIONAL = True\n",
    "ENC_BIDIRECTIONAL_FACTOR = 2 if ENC_BIDIRECTIONAL else 1\n",
    "ENC_HIDDEN_DIM = 256\n",
    "DEC_HIDDEN_DIM  = 256\n",
    "ENC_OUTPUT_DIM =  DEC_HIDDEN_DIM\n",
    "DEC_EMBED_DIM = 300\n",
    "NUM_EPOCHS = 300\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "device_fast = torch.device('cpu')\n",
    "\n",
    "if torch.has_mps:\n",
    "    device_fast = torch.device('mps')\n",
    "elif torch.has_cuda:\n",
    "    device_fast = torch.device('cuda')\n",
    "\n",
    "\n",
    "output_index_to_word = {}\n",
    "output_vocab = {}\n",
    "\n",
    "for i in range(0,10):\n",
    "    output_vocab[str(i)] = i\n",
    "    output_index_to_word[i] = str(i)\n",
    "\n",
    "output_vocab['-'] = 10\n",
    "output_index_to_word[10] = '-'\n",
    "output_vocab['<sos>'] = 11\n",
    "output_index_to_word[11] = '<sos>'\n",
    "output_vocab['<eos>'] = 12\n",
    "output_index_to_word[12] = '<eos>'\n",
    "\n",
    "glove = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_data(filename='./Assignment4aDataset.txt',glove=glove):\n",
    "    \n",
    "    f = open(filename,'r')\n",
    "    dataset = []\n",
    "    for line in f.readlines():       \n",
    "         \n",
    "        nl_date , out_date = line.split(',')\n",
    "        nl_date = nl_date.replace(\"\\'\",\"\").strip()\n",
    "        out_date = out_date.replace(\"\\'\",\"\").strip()\n",
    "\n",
    "        if \"/\" in nl_date:\n",
    "            #number_list = list(nl_date)\n",
    "            #nl_date = \" \".join(number_list)\n",
    "            split_on_slash = nl_date.split(\"/\")\n",
    "            nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "        nl_date = nl_date.lower()\n",
    "\n",
    "        embeddings = []\n",
    "        for word in nl_date.split(' '):\n",
    "            if word == '':\n",
    "                continue\n",
    "            embeddings.append(glove[word])\n",
    "            #embeddings.append(torch.tensor(fasttext_model.get_word_vector(word)))\n",
    "        current_inp_length = len(embeddings)\n",
    "        embeddings = torch.stack(embeddings)\n",
    "\n",
    "        target = []\n",
    "        target.append(output_vocab['<sos>'])\n",
    "\n",
    "        for character in list(out_date):\n",
    "            target.append(output_vocab[character])\n",
    "        \n",
    "        target.append(output_vocab['<eos>'])\n",
    "\n",
    "        dataset.append({'in' : embeddings,'in_length' : current_inp_length,'out' : target})\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_function(batch_data):\n",
    "    inputs = [b['in'] for b in batch_data]\n",
    "    in_lengths = [b['in_length'] for b in batch_data]\n",
    "    out = torch.tensor([b['out'] for b in batch_data])\n",
    "    inputs = pad_sequence(inputs,batch_first=True)\n",
    "    return {'src': inputs, 'src_length' : in_lengths, 'trg' : out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(get_training_data())\n",
    "\n",
    "train_idx,valid_idx = train_test_split(np.arange(len(train_dataset)), \n",
    "    test_size=0.2,\n",
    "    shuffle= True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_dataloader = DataLoader(train_dataset,BATCH_SIZE,sampler=train_sampler,collate_fn=collate_function)\n",
    "valid_dataloader = DataLoader(train_dataset,BATCH_SIZE,sampler=valid_sampler,collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,embed_dim = EMBED_DIM,enc_hidden_dim = ENC_HIDDEN_DIM,enc_output_dim = ENC_OUTPUT_DIM,NUM_LAYERS=1,enc_bidirectional=ENC_BIDIRECTIONAL,dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.embedding_layer = nn.Embedding(vocab_size,EMBED_DIM)\n",
    "        self.rnn = nn.GRU(embed_dim,enc_hidden_dim, num_layers = NUM_LAYERS ,batch_first= True ,bidirectional=enc_bidirectional)\n",
    "\n",
    "\n",
    "        # ENCODER_OUTPUT_DIM = DECODER_HIDDEN_SIZE\n",
    "        self.fc = nn.Linear(2*enc_hidden_dim,enc_output_dim) \n",
    "\n",
    "        self.fc_out = nn.Linear(enc_output_dim,1)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,inp,inp_len):\n",
    "        \n",
    "        #embedded_input = self.embedding_layer(inp)\n",
    "        embedded_input = inp   # [batch_size, input_seq_length, embed_dim ]\n",
    "        \n",
    "        packed_embedding = nn.utils.rnn.pack_padded_sequence(embedded_input,inp_len,batch_first=True,enforce_sorted=False)\n",
    "        packed_output , hidden = self.rnn(packed_embedding)  # hidden = [D*num_layers, batch_size , hidden_dim ]\n",
    "        outputs, _  = nn.utils.rnn.pad_packed_sequence(packed_output,batch_first=True)  # [batch_size, inp_seq_length, hidden_dim]\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1)))  # [batch_size, decoder_hidden_size]\n",
    "        return outputs,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear(enc_hidden_dim+dec_hidden_dim,dec_hidden_dim)\n",
    "        self.v = nn.Linear(dec_hidden_dim,1)\n",
    "\n",
    "    def forward(self,hidden,encoder_outputs, encoder_length_mask):\n",
    "        \n",
    "        # encoder_outputs = [batch_size,seq_length, enc_hidden_dim][2*ENCODER_HIDDEN_DIM or ENCODER_HIDDEN_DIM]\n",
    "        # hidden = [batch_size,  dec_hidden_dim]\n",
    "        # encoder_length_mask = [batch_size, seq_length]\n",
    "\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        h = hidden.unsqueeze(1).repeat(1,src_len,1)  # h = [batch_size,seq_length,dec_hidden_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((h,encoder_outputs),dim=2)))  #[batch_size,seq_length,dec_hidden_dim]\n",
    "        attention_scores = self.v(energy).squeeze(2)  # attention_scores = [batch_size , seq_length ]\n",
    "        attention_scores = attention_scores.masked_fill(encoder_length_mask==1, -1e10)   # Fill padding tokens with a lower value\n",
    "        attention_scores = F.softmax(attention_scores,dim=1)\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src_lengths,max_src_length):\n",
    "\n",
    "        src_mask = torch.zeros((len(src_lengths),max_src_length),dtype=torch.int64)\n",
    "        for i in range(len(src_lengths)):\n",
    "\n",
    "            src_mask[i,src_lengths[i]:] = 1\n",
    "        return src_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enc = Encoder(30,30,15,10)\n",
    "\n",
    "inp = torch.randn((3,20,30))\n",
    "inp_len = [20 for i in range(3)]\n",
    "outputs, hidden = enc(inp,inp_len)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,enc_hidden_dim,dec_hidden_dim,dec_output_dim,emb_dim):\n",
    "        \n",
    "        # enc_hidden_dim = 2*ENCODER_HIDDEN_DIM or ENCODER_HIDDEN_DIM\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.attention = Attention(enc_hidden_dim,dec_hidden_dim)\n",
    "        self.embedding_layer = nn.Embedding(vocab_size,emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hidden_dim + emb_dim,dec_hidden_dim,batch_first = True)\n",
    "\n",
    "        self.fc_out = nn.Linear(enc_hidden_dim + emb_dim + dec_hidden_dim , dec_output_dim)\n",
    "        \n",
    "        #self.fc_tilde = nn.Linear(enc_hidden_dim + emb_dim + dec_hidden_dim , dec_hidden_dim)\n",
    "        #self.max_out_layer = nn.MaxPool1d(kernel_size=2)\n",
    "        #self.W0 = nn.Linear(dec_hidden_dim>>1,emb_dim)\n",
    "        #self.prob_out = nn.Linear(emb_dim,vocab_size)\n",
    "        #self.prob_out.weight = self.embedding_layer.weight\n",
    "        \n",
    "\n",
    "    def forward(self,input,hidden,encoder_outputs,encoder_length_mask):\n",
    "            # encoder outputs =  batch_size , seq_len , encoder_output_dim\n",
    "            # hidden = batch_size , hidden_dim\n",
    "            # input = batch_size\n",
    "            \n",
    "            input = input.unsqueeze(0) # [1,batch_size]\n",
    "            embedded = self.embedding_layer(input) # [1,batch_size,embed_dim]\n",
    "\n",
    "            embedded = embedded.permute(1,0,2) #[ batch_size, seq_length=1, embed_dim ]\n",
    "\n",
    "            attention_vector = self.attention(hidden,encoder_outputs,encoder_length_mask) # [ batch_size , seq_length ]\n",
    "            attention_vector = attention_vector.unsqueeze(1) # [batch_size , 1 , seq_length ]\n",
    "\n",
    "            weighted = torch.bmm(attention_vector,encoder_outputs) # [ batch_size, 1, encoder_output_dim]\n",
    "            #weighted = weighted.permute(1,0,2) #[1 , batch_size , encoder_output_dim]\n",
    "\n",
    "\n",
    "            rnn_input = torch.cat((embedded,weighted),dim=2) #[batch_size, seq_length=1, encoder + decoder]\n",
    "\n",
    "            out,h = self.rnn(rnn_input,hidden.unsqueeze(0)) # consider only a single layer (1.) so unsqueeze(0)\n",
    "\n",
    "            # out = [batch_size, seq_length = 1, decoder_hidden_out (bidirectional)]\n",
    "            # hidden = [D*num_layers,batch_size, decoder_hidden_out]\n",
    "\n",
    "\n",
    "            embedded = embedded.squeeze(1)  # [batch_size,embed_dim]\n",
    "            out = out.squeeze(1)    #[batch_size, decoder_hidden_out] # Have to change if the number of layers is changed to more than 1\n",
    "            weighted = weighted.squeeze(1)  # [batch_size,encoder_output_dim] \n",
    "            prediction = self.fc_out(torch.cat([embedded,out,weighted],dim=1)) #[batch_size, decoder_output_dim]\n",
    "            \n",
    "            \n",
    "            #prediction = F.softmax(self.fc_out(torch.cat([embedded,out,weighted],dim=1)),dim=1) #[batch_size, decoder_output_dim]\n",
    "            #t_tilde =  self.fc_tilde(torch.cat([embedded,out,weighted],dim=1)) # [batch_size, decoder_hidden_dim]\n",
    "            #t_tilde = self.max_out_layer(t_tilde.unsqueeze(1)) #[batch_size,1,decoder_hidden_dim/2]\n",
    "            #t_tilde = t_tilde.squeeze(1)\n",
    "\n",
    "            #inter_step  = self.W0(t_tilde) # [ batch_size , dec_embeddim]\n",
    "            #prediction = self.prob_out(inter_step) #[  batch_size , vocab_size]\n",
    "            #prediction = F.softmax(prediction,dim=1)\n",
    "            return prediction, h.squeeze(0), attention_vector # Reduce the number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                input_embed_dim = EMBED_DIM,\n",
    "                encoder_hidden_dim = ENC_HIDDEN_DIM,\n",
    "                encoder_hidden_output = ENC_OUTPUT_DIM,\n",
    "                enc_num_layers = 1,\n",
    "                enc_bidirectional = ENC_BIDIRECTIONAL,\n",
    "\n",
    "                dec_vocab_size = len(output_vocab),\n",
    "                dec_embed_dim = DEC_EMBED_DIM,\n",
    "                dec_hidden_dim  =DEC_HIDDEN_DIM,\n",
    "                device_train = device_cpu\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_embed_dim,encoder_hidden_dim,encoder_hidden_output,enc_num_layers,enc_bidirectional=enc_bidirectional)\n",
    "        enc_bidirectional_factor = 2 if enc_bidirectional else 1\n",
    "        self.decoder = Decoder(dec_vocab_size,enc_bidirectional_factor*encoder_hidden_dim,dec_hidden_dim=dec_hidden_dim,dec_output_dim=dec_vocab_size,emb_dim=dec_embed_dim)\n",
    "        self.device_train = device_train\n",
    "\n",
    "\n",
    "    def create_mask(self, src_lengths,max_src_length):\n",
    "\n",
    "        src_mask = torch.zeros((len(src_lengths),max_src_length),dtype=torch.int64)\n",
    "        for i in range(len(src_lengths)):\n",
    "\n",
    "            src_mask[i,src_lengths[i]:] = 1\n",
    "        return src_mask\n",
    "        \n",
    "    def forward(self,source,source_len,target,teacher_forcing_ratio = 0.0):\n",
    "        #   source = [batch_size, max_src_len]\n",
    "        #   source_len = [length of sentence in the batch]\n",
    "        #   target = [batch_size,traget_length]\n",
    "        #   teacher_forcing_ratio = probability to use teacher forcinbg\n",
    "\n",
    "        batch_size = source.shape[0]\n",
    "        target_length = target.shape[1]\n",
    "        target_vocab_size = self.decoder.vocab_size\n",
    "        outputs= torch.zeros(batch_size,target_length,target_vocab_size).to(self.device_train)\n",
    "        encoder_outputs , hidden = self.encoder(source,source_len)\n",
    "\n",
    "        inp = target[:,0]        \n",
    "        enc_mask = self.create_mask(source_len,int(encoder_outputs.shape[1]))\n",
    "        enc_mask = enc_mask.to(self.device_train)\n",
    "        for t in range(1,target_length):\n",
    "            decoder_output, hidden, attention_vector =  self.decoder(inp,hidden,encoder_outputs,enc_mask)\n",
    "\n",
    "            outputs[:,t,:] = decoder_output # batch_size, vocab_size\n",
    "            teacher_force = random.random() < teacher_forcing_ratio \n",
    "\n",
    "            top1 = decoder_output.argmax(1)\n",
    "\n",
    "            inp = target[:,t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weights(model : TranslationModel):\n",
    "    \n",
    "    for name,param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data,mean=0,std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data,0)\n",
    "    \n",
    "    \n",
    "    nn.init.xavier_uniform_(model.encoder.fc_out.weight)\n",
    "    nn.init.normal_(model.decoder.attention.attn.weight, mean=0, std=0.001)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = TranslationModel()\n",
    "apply_weights(t)\n",
    "batch_data = next(iter(train_dataloader))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=output_vocab['<eos>'])\n",
    "optimizer = optim.Adam(t.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "model_output = t(batch_data['src'],batch_data['src_length'],batch_data['trg'])\n",
    "\n",
    "\n",
    "model_out_reshaped = model_output[1:].view(-1,model_output.shape[-1])\n",
    "reshaped_target = batch_data['trg'][1:].view(-1)\n",
    "loss_value = criterion(model_out_reshaped,reshaped_target)\n",
    "loss_value.backward()\n",
    "nn.utils.clip_grad_norm_(t.parameters(),5)\n",
    "optimizer.step()\n",
    "print(loss_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import  datetime\n",
    "\n",
    "import os\n",
    "\n",
    "def train_model(model,num_epochs,train_loader,valid_loader,optimizer,criterion,checkpoint_name='translation_model.pth',device_train = device_cpu):\n",
    "    \n",
    "    current_datetime = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    tensorboard_name =  checkpoint_name + current_datetime\n",
    "    writer = SummaryWriter(os.getcwd() +'\\\\runs\\\\' + tensorboard_name)\n",
    "\n",
    "    best_validation_loss = 1000.0\n",
    "    model = model.to(device_train)\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        model.train()\n",
    "        for i,batch in enumerate(train_loader):\n",
    "\n",
    "            source, source_length, target = batch['src'], batch['src_length'], batch['trg']\n",
    "\n",
    "            source = source.to(device_train)\n",
    "            target = target.to(device_train)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # model_output = [batch_size, output_seq_length,vocab_size]\n",
    "            model_output  = model(source,source_length,target)\n",
    "\n",
    "\n",
    "            source = source.to(device_cpu)\n",
    "            target = target.to(device_cpu)\n",
    "            model_output = model_output.to(device_cpu)\n",
    "            \n",
    "            model_out_reshaped = model_output[1:].view(-1,model_output.shape[-1]) \n",
    "            #print(model_out_reshaped.shape)\n",
    "            reshaped_target = target[1:].view(-1)\n",
    "            #print(reshaped_target.shape)\n",
    "\n",
    "            loss_value = criterion(model_out_reshaped,reshaped_target)\n",
    "            loss_value.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),5)\n",
    "\n",
    "            optimizer.step()\n",
    "            training_loss += loss_value.item()\n",
    "        \n",
    "        print(\"Epoch \" + str(e) + \" Training Loss Value = \" + str(training_loss/len(train_loader)))\n",
    "        writer.add_scalars('Train/Loss vs Epoch',{'train' :training_loss/len(train_loader)},e)\n",
    "\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i, batch in enumerate(valid_loader):\n",
    "                source, source_length, target = batch['src'], batch['src_length'], batch['trg']\n",
    "\n",
    "                source = source.to(device_train)\n",
    "                target = target.to(device_train)\n",
    "\n",
    "                model_output  = model(source,source_length,target,0)\n",
    "\n",
    "\n",
    "                source = source.to(device_cpu)\n",
    "                target = target.to(device_cpu)\n",
    "                model_output = model_output.to(device_cpu)\n",
    "                \n",
    "                model_out_reshaped = model_output[1:].view(-1,model_output.shape[-1])\n",
    "                reshaped_target = target[1:].view(-1)\n",
    "                loss_value = criterion(model_out_reshaped,reshaped_target)\n",
    "\n",
    "                validation_loss += loss_value.item()\n",
    "        averaged_validation_loss = validation_loss/len(valid_loader)\n",
    "        writer.add_scalars('Train/Loss vs Epoch',{'valid' :averaged_validation_loss},e)\n",
    "\n",
    "        print(\"Epoch \" + str(e) + \" Validation Loss Value = \" + str(averaged_validation_loss))\n",
    "        print(\"\")\n",
    "        if (averaged_validation_loss <= best_validation_loss):\n",
    "            best_validation_loss = averaged_validation_loss\n",
    "            torch.save(model.state_dict(),checkpoint_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss Value = 1.163891459941864\n",
      "Epoch 0 Validation Loss Value = 0.5932923158009847\n",
      "\n",
      "Epoch 1 Training Loss Value = 0.45339826226234436\n",
      "Epoch 1 Validation Loss Value = 0.35730191071828205\n",
      "\n",
      "Epoch 2 Training Loss Value = 0.3102092615365982\n",
      "Epoch 2 Validation Loss Value = 0.2731743710381644\n",
      "\n",
      "Epoch 3 Training Loss Value = 0.25460091143846514\n",
      "Epoch 3 Validation Loss Value = 0.2462291663128232\n",
      "\n",
      "Epoch 4 Training Loss Value = 0.23632875949144364\n",
      "Epoch 4 Validation Loss Value = 0.23963613216839139\n",
      "\n",
      "Epoch 5 Training Loss Value = 0.27409595507383344\n",
      "Epoch 5 Validation Loss Value = 0.2315670999269637\n",
      "\n",
      "Epoch 6 Training Loss Value = 0.22873130881786347\n",
      "Epoch 6 Validation Loss Value = 0.22683260388790616\n",
      "\n",
      "Epoch 7 Training Loss Value = 0.22682017707824706\n",
      "Epoch 7 Validation Loss Value = 0.2327646166086197\n",
      "\n",
      "Epoch 8 Training Loss Value = 0.2267318130135536\n",
      "Epoch 8 Validation Loss Value = 0.225244991363041\n",
      "\n",
      "Epoch 9 Training Loss Value = 0.22402387470006943\n",
      "Epoch 9 Validation Loss Value = 0.2243365002056909\n",
      "\n",
      "Epoch 10 Training Loss Value = 0.22558936250209807\n",
      "Epoch 10 Validation Loss Value = 0.22433994426613763\n",
      "\n",
      "Epoch 11 Training Loss Value = 0.2234400913119316\n",
      "Epoch 11 Validation Loss Value = 0.22507983304205395\n",
      "\n",
      "Epoch 12 Training Loss Value = 0.22683608347177506\n",
      "Epoch 12 Validation Loss Value = 0.22686643070644802\n",
      "\n",
      "Epoch 13 Training Loss Value = 0.2233030356168747\n",
      "Epoch 13 Validation Loss Value = 0.22373271674390824\n",
      "\n",
      "Epoch 14 Training Loss Value = 0.22267759007215499\n",
      "Epoch 14 Validation Loss Value = 0.2258774713864402\n",
      "\n",
      "Epoch 15 Training Loss Value = 0.22361926656961442\n",
      "Epoch 15 Validation Loss Value = 0.22412962123515115\n",
      "\n",
      "Epoch 16 Training Loss Value = 0.2235048635005951\n",
      "Epoch 16 Validation Loss Value = 0.2250488575488802\n",
      "\n",
      "Epoch 17 Training Loss Value = 0.22642813074588775\n",
      "Epoch 17 Validation Loss Value = 0.22380445873926555\n",
      "\n",
      "Epoch 18 Training Loss Value = 0.22211402934789656\n",
      "Epoch 18 Validation Loss Value = 0.22292590377822755\n",
      "\n",
      "Epoch 19 Training Loss Value = 0.22261916947364807\n",
      "Epoch 19 Validation Loss Value = 0.22308496492249624\n",
      "\n",
      "Epoch 20 Training Loss Value = 0.2219785475730896\n",
      "Epoch 20 Validation Loss Value = 0.2231141979259158\n",
      "\n",
      "Epoch 21 Training Loss Value = 0.22162844842672347\n",
      "Epoch 21 Validation Loss Value = 0.22497144554342544\n",
      "\n",
      "Epoch 22 Training Loss Value = 0.22533301216363907\n",
      "Epoch 22 Validation Loss Value = 0.22396978735923767\n",
      "\n",
      "Epoch 23 Training Loss Value = 0.22182473665475846\n",
      "Epoch 23 Validation Loss Value = 0.2269723221423134\n",
      "\n",
      "Epoch 24 Training Loss Value = 0.22227880042791368\n",
      "Epoch 24 Validation Loss Value = 0.22365986662251608\n",
      "\n",
      "Epoch 25 Training Loss Value = 0.22082265019416808\n",
      "Epoch 25 Validation Loss Value = 0.22628149532136463\n",
      "\n",
      "Epoch 26 Training Loss Value = 0.2218006562590599\n",
      "Epoch 26 Validation Loss Value = 0.2235356585847007\n",
      "\n",
      "Epoch 27 Training Loss Value = 0.230875850379467\n",
      "Epoch 27 Validation Loss Value = 0.22439640240063743\n",
      "\n",
      "Epoch 28 Training Loss Value = 0.22099772453308106\n",
      "Epoch 28 Validation Loss Value = 0.22353901158249567\n",
      "\n",
      "Epoch 29 Training Loss Value = 0.22027305620908738\n",
      "Epoch 29 Validation Loss Value = 0.22278230057822335\n",
      "\n",
      "Epoch 30 Training Loss Value = 0.22003414344787597\n",
      "Epoch 30 Validation Loss Value = 0.22400078934336465\n",
      "\n",
      "Epoch 31 Training Loss Value = 0.22025696682929993\n",
      "Epoch 31 Validation Loss Value = 0.2228526281458991\n",
      "\n",
      "Epoch 32 Training Loss Value = 0.22039578008651733\n",
      "Epoch 32 Validation Loss Value = 0.224127159232185\n",
      "\n",
      "Epoch 33 Training Loss Value = 0.2200276472568512\n",
      "Epoch 33 Validation Loss Value = 0.2240178639453555\n",
      "\n",
      "Epoch 34 Training Loss Value = 0.22196795427799224\n",
      "Epoch 34 Validation Loss Value = 0.23533792699140216\n",
      "\n",
      "Epoch 35 Training Loss Value = 0.22226448613405228\n",
      "Epoch 35 Validation Loss Value = 0.22614303798902602\n",
      "\n",
      "Epoch 36 Training Loss Value = 0.2200836550593376\n",
      "Epoch 36 Validation Loss Value = 0.23029236400884295\n",
      "\n",
      "Epoch 37 Training Loss Value = 0.22173547488451004\n",
      "Epoch 37 Validation Loss Value = 0.22394309062806386\n",
      "\n",
      "Epoch 38 Training Loss Value = 0.21940281254053115\n",
      "Epoch 38 Validation Loss Value = 0.22372823527881078\n",
      "\n",
      "Epoch 39 Training Loss Value = 0.21904044884443283\n",
      "Epoch 39 Validation Loss Value = 0.22368602975020332\n",
      "\n",
      "Epoch 40 Training Loss Value = 0.21904244804382325\n",
      "Epoch 40 Validation Loss Value = 0.22446611168838682\n",
      "\n",
      "Epoch 41 Training Loss Value = 0.21973900836706162\n",
      "Epoch 41 Validation Loss Value = 0.22806663243543535\n",
      "\n",
      "Epoch 42 Training Loss Value = 0.2222504006624222\n",
      "Epoch 42 Validation Loss Value = 0.22526705525224172\n",
      "\n",
      "Epoch 43 Training Loss Value = 0.21879346024990082\n",
      "Epoch 43 Validation Loss Value = 0.22543402536520882\n",
      "\n",
      "Epoch 44 Training Loss Value = 0.2187795102596283\n",
      "Epoch 44 Validation Loss Value = 0.2284431748446964\n",
      "\n",
      "Epoch 45 Training Loss Value = 0.21992403668165206\n",
      "Epoch 45 Validation Loss Value = 0.2279129825414173\n",
      "\n",
      "Epoch 46 Training Loss Value = 0.21823007619380952\n",
      "Epoch 46 Validation Loss Value = 0.22539958263200427\n",
      "\n",
      "Epoch 47 Training Loss Value = 0.21774346375465392\n",
      "Epoch 47 Validation Loss Value = 0.22507985220068977\n",
      "\n",
      "Epoch 48 Training Loss Value = 0.21768017166852952\n",
      "Epoch 48 Validation Loss Value = 0.22656274977184476\n",
      "\n",
      "Epoch 49 Training Loss Value = 0.22065845429897307\n",
      "Epoch 49 Validation Loss Value = 0.2261717908439182\n",
      "\n",
      "Epoch 50 Training Loss Value = 0.21773751968145372\n",
      "Epoch 50 Validation Loss Value = 0.2270435622287175\n",
      "\n",
      "Epoch 51 Training Loss Value = 0.21679729336500167\n",
      "Epoch 51 Validation Loss Value = 0.22728241909117924\n",
      "\n",
      "Epoch 52 Training Loss Value = 0.21678946441411973\n",
      "Epoch 52 Validation Loss Value = 0.22650890927466136\n",
      "\n",
      "Epoch 53 Training Loss Value = 0.2166284214258194\n",
      "Epoch 53 Validation Loss Value = 0.22705637273334323\n",
      "\n",
      "Epoch 54 Training Loss Value = 0.21621649599075318\n",
      "Epoch 54 Validation Loss Value = 0.22709055292227912\n",
      "\n",
      "Epoch 55 Training Loss Value = 0.2191092785000801\n",
      "Epoch 55 Validation Loss Value = 0.22802459058307467\n",
      "\n",
      "Epoch 56 Training Loss Value = 0.2168004054427147\n",
      "Epoch 56 Validation Loss Value = 0.2279415111693125\n",
      "\n",
      "Epoch 57 Training Loss Value = 0.2157588706612587\n",
      "Epoch 57 Validation Loss Value = 0.2280134158948111\n",
      "\n",
      "Epoch 58 Training Loss Value = 0.21545172959566117\n",
      "Epoch 58 Validation Loss Value = 0.22835934375013625\n",
      "\n",
      "Epoch 59 Training Loss Value = 0.21560834842920304\n",
      "Epoch 59 Validation Loss Value = 0.22953641722126614\n",
      "\n",
      "Epoch 60 Training Loss Value = 0.21596241211891173\n",
      "Epoch 60 Validation Loss Value = 0.2295882607263232\n",
      "\n",
      "Epoch 61 Training Loss Value = 0.22333210855722427\n",
      "Epoch 61 Validation Loss Value = 0.22874377880777633\n",
      "\n",
      "Epoch 62 Training Loss Value = 0.21579602146148683\n",
      "Epoch 62 Validation Loss Value = 0.22935362585953303\n",
      "\n",
      "Epoch 63 Training Loss Value = 0.2147362518310547\n",
      "Epoch 63 Validation Loss Value = 0.23038992593212734\n",
      "\n",
      "Epoch 64 Training Loss Value = 0.21455486059188844\n",
      "Epoch 64 Validation Loss Value = 0.2297941358789565\n",
      "\n",
      "Epoch 65 Training Loss Value = 0.2145548951625824\n",
      "Epoch 65 Validation Loss Value = 0.22985267804728615\n",
      "\n",
      "Epoch 66 Training Loss Value = 0.21442005735635758\n",
      "Epoch 66 Validation Loss Value = 0.23038660604802388\n",
      "\n",
      "Epoch 67 Training Loss Value = 0.2144200124144554\n",
      "Epoch 67 Validation Loss Value = 0.23065308209449525\n",
      "\n",
      "Epoch 68 Training Loss Value = 0.21496375000476836\n",
      "Epoch 68 Validation Loss Value = 0.23022103711726175\n",
      "\n",
      "Epoch 69 Training Loss Value = 0.2207693462371826\n",
      "Epoch 69 Validation Loss Value = 0.23276009564361874\n",
      "\n",
      "Epoch 70 Training Loss Value = 0.21683268225193023\n",
      "Epoch 70 Validation Loss Value = 0.22978765032594167\n",
      "\n",
      "Epoch 71 Training Loss Value = 0.21493154561519623\n",
      "Epoch 71 Validation Loss Value = 0.23073599664937883\n",
      "\n",
      "Epoch 72 Training Loss Value = 0.21443500638008117\n",
      "Epoch 72 Validation Loss Value = 0.2313382230580799\n",
      "\n",
      "Epoch 73 Training Loss Value = 0.21422055178880692\n",
      "Epoch 73 Validation Loss Value = 0.23137892829993414\n",
      "\n",
      "Epoch 74 Training Loss Value = 0.21411046850681306\n",
      "Epoch 74 Validation Loss Value = 0.23155110956184446\n",
      "\n",
      "Epoch 75 Training Loss Value = 0.21411842185258864\n",
      "Epoch 75 Validation Loss Value = 0.23202887295730532\n",
      "\n",
      "Epoch 76 Training Loss Value = 0.21690596568584442\n",
      "Epoch 76 Validation Loss Value = 0.23206997816524808\n",
      "\n",
      "Epoch 77 Training Loss Value = 0.21985623639822005\n",
      "Epoch 77 Validation Loss Value = 0.23300630256297097\n",
      "\n",
      "Epoch 78 Training Loss Value = 0.21525310015678406\n",
      "Epoch 78 Validation Loss Value = 0.2319826218816969\n",
      "\n",
      "Epoch 79 Training Loss Value = 0.2144774003624916\n",
      "Epoch 79 Validation Loss Value = 0.23165342211723328\n",
      "\n",
      "Epoch 80 Training Loss Value = 0.21427088528871535\n",
      "Epoch 80 Validation Loss Value = 0.23138633985368032\n",
      "\n",
      "Epoch 81 Training Loss Value = 0.21417823666334151\n",
      "Epoch 81 Validation Loss Value = 0.2330140835709042\n",
      "\n",
      "Epoch 82 Training Loss Value = 0.2141148833632469\n",
      "Epoch 82 Validation Loss Value = 0.233067159141813\n",
      "\n",
      "Epoch 83 Training Loss Value = 0.2140994262099266\n",
      "Epoch 83 Validation Loss Value = 0.23286148692880357\n",
      "\n",
      "Epoch 84 Training Loss Value = 0.21414437115192414\n",
      "Epoch 84 Validation Loss Value = 0.23286941316392687\n",
      "\n",
      "Epoch 85 Training Loss Value = 0.2141483971476555\n",
      "Epoch 85 Validation Loss Value = 0.2336273046713027\n",
      "\n",
      "Epoch 86 Training Loss Value = 0.22069242066144942\n",
      "Epoch 86 Validation Loss Value = 0.2348033468874674\n",
      "\n",
      "Epoch 87 Training Loss Value = 0.22315661334991455\n",
      "Epoch 87 Validation Loss Value = 0.23110201481788878\n",
      "\n",
      "Epoch 88 Training Loss Value = 0.215112539768219\n",
      "Epoch 88 Validation Loss Value = 0.23165212926410494\n",
      "\n",
      "Epoch 89 Training Loss Value = 0.21439124703407286\n",
      "Epoch 89 Validation Loss Value = 0.23167387857323601\n",
      "\n",
      "Epoch 90 Training Loss Value = 0.21413544648885727\n",
      "Epoch 90 Validation Loss Value = 0.23161099732868254\n",
      "\n",
      "Epoch 91 Training Loss Value = 0.2140576692223549\n",
      "Epoch 91 Validation Loss Value = 0.23183718512928675\n",
      "\n",
      "Epoch 92 Training Loss Value = 0.2140329893231392\n",
      "Epoch 92 Validation Loss Value = 0.2320491342790543\n",
      "\n",
      "Epoch 93 Training Loss Value = 0.21403608578443528\n",
      "Epoch 93 Validation Loss Value = 0.23235849705007341\n",
      "\n",
      "Epoch 94 Training Loss Value = 0.21403654158115387\n",
      "Epoch 94 Validation Loss Value = 0.23245721369508712\n",
      "\n",
      "Epoch 95 Training Loss Value = 0.21400348365306854\n",
      "Epoch 95 Validation Loss Value = 0.23297111595433856\n",
      "\n",
      "Epoch 96 Training Loss Value = 0.21413470649719238\n",
      "Epoch 96 Validation Loss Value = 0.23420850483198014\n",
      "\n",
      "Epoch 97 Training Loss Value = 0.22014334905147553\n",
      "Epoch 97 Validation Loss Value = 0.23559796360750046\n",
      "\n",
      "Epoch 98 Training Loss Value = 0.21863309121131896\n",
      "Epoch 98 Validation Loss Value = 0.23076316927160537\n",
      "\n",
      "Epoch 99 Training Loss Value = 0.21579596495628356\n",
      "Epoch 99 Validation Loss Value = 0.23231565904995752\n",
      "\n",
      "Epoch 100 Training Loss Value = 0.21471531826257706\n",
      "Epoch 100 Validation Loss Value = 0.23182209332784018\n",
      "\n",
      "Epoch 101 Training Loss Value = 0.21424694216251372\n",
      "Epoch 101 Validation Loss Value = 0.2326977179637031\n",
      "\n",
      "Epoch 102 Training Loss Value = 0.2140781751871109\n",
      "Epoch 102 Validation Loss Value = 0.23399916125668418\n",
      "\n",
      "Epoch 103 Training Loss Value = 0.21402297329902648\n",
      "Epoch 103 Validation Loss Value = 0.23324797290658195\n",
      "\n",
      "Epoch 104 Training Loss Value = 0.21401162433624268\n",
      "Epoch 104 Validation Loss Value = 0.234284285042021\n",
      "\n",
      "Epoch 105 Training Loss Value = 0.2140220514535904\n",
      "Epoch 105 Validation Loss Value = 0.234193112642046\n",
      "\n",
      "Epoch 106 Training Loss Value = 0.21403170120716095\n",
      "Epoch 106 Validation Loss Value = 0.23504504206634702\n",
      "\n",
      "Epoch 107 Training Loss Value = 0.21414447116851806\n",
      "Epoch 107 Validation Loss Value = 0.23484213815795052\n",
      "\n",
      "Epoch 108 Training Loss Value = 0.21414474618434906\n",
      "Epoch 108 Validation Loss Value = 0.23403597942420415\n",
      "\n",
      "Epoch 109 Training Loss Value = 0.22281667304039002\n",
      "Epoch 109 Validation Loss Value = 0.2330706034387861\n",
      "\n",
      "Epoch 110 Training Loss Value = 0.2167411050796509\n",
      "Epoch 110 Validation Loss Value = 0.23293040929332612\n",
      "\n",
      "Epoch 111 Training Loss Value = 0.21461533123254775\n",
      "Epoch 111 Validation Loss Value = 0.23436971008777618\n",
      "\n",
      "Epoch 112 Training Loss Value = 0.21439735120534897\n",
      "Epoch 112 Validation Loss Value = 0.23419713571904197\n",
      "\n",
      "Epoch 113 Training Loss Value = 0.21408015197515487\n",
      "Epoch 113 Validation Loss Value = 0.2349059446936562\n",
      "\n",
      "Epoch 114 Training Loss Value = 0.21403804904222487\n",
      "Epoch 114 Validation Loss Value = 0.235425709022416\n",
      "\n",
      "Epoch 115 Training Loss Value = 0.21398634493350982\n",
      "Epoch 115 Validation Loss Value = 0.23539839637657953\n",
      "\n",
      "Epoch 116 Training Loss Value = 0.21399081319570543\n",
      "Epoch 116 Validation Loss Value = 0.2356251019334036\n",
      "\n",
      "Epoch 117 Training Loss Value = 0.2140025771856308\n",
      "Epoch 117 Validation Loss Value = 0.23569146910357097\n",
      "\n",
      "Epoch 118 Training Loss Value = 0.2139886507987976\n",
      "Epoch 118 Validation Loss Value = 0.23595230801711006\n",
      "\n",
      "Epoch 119 Training Loss Value = 0.21398820519447326\n",
      "Epoch 119 Validation Loss Value = 0.2361456531853903\n",
      "\n",
      "Epoch 120 Training Loss Value = 0.21468557012081146\n",
      "Epoch 120 Validation Loss Value = 0.2361960888855041\n",
      "\n",
      "Epoch 121 Training Loss Value = 0.22240169978141786\n",
      "Epoch 121 Validation Loss Value = 0.23344675132206508\n",
      "\n",
      "Epoch 122 Training Loss Value = 0.21672395795583724\n",
      "Epoch 122 Validation Loss Value = 0.23425608542230394\n",
      "\n",
      "Epoch 123 Training Loss Value = 0.21512448233366013\n",
      "Epoch 123 Validation Loss Value = 0.23470429248279995\n",
      "\n",
      "Epoch 124 Training Loss Value = 0.21455635219812394\n",
      "Epoch 124 Validation Loss Value = 0.23393351028835963\n",
      "\n",
      "Epoch 125 Training Loss Value = 0.21417533659934998\n",
      "Epoch 125 Validation Loss Value = 0.23376315737527514\n",
      "\n",
      "Epoch 126 Training Loss Value = 0.2140711579322815\n",
      "Epoch 126 Validation Loss Value = 0.23438688521347348\n",
      "\n",
      "Epoch 127 Training Loss Value = 0.21400744777917863\n",
      "Epoch 127 Validation Loss Value = 0.23505812339366428\n",
      "\n",
      "Epoch 128 Training Loss Value = 0.21397935169935225\n",
      "Epoch 128 Validation Loss Value = 0.23570159101296986\n",
      "\n",
      "Epoch 129 Training Loss Value = 0.21399413692951202\n",
      "Epoch 129 Validation Loss Value = 0.23577859004338583\n",
      "\n",
      "Epoch 130 Training Loss Value = 0.21395771312713624\n",
      "Epoch 130 Validation Loss Value = 0.2354870280103078\n",
      "\n",
      "Epoch 131 Training Loss Value = 0.21403934770822525\n",
      "Epoch 131 Validation Loss Value = 0.23584489855501387\n",
      "\n",
      "Epoch 132 Training Loss Value = 0.21420988631248475\n",
      "Epoch 132 Validation Loss Value = 0.23500753418793754\n",
      "\n",
      "Epoch 133 Training Loss Value = 0.2237069684267044\n",
      "Epoch 133 Validation Loss Value = 0.23352950456596555\n",
      "\n",
      "Epoch 134 Training Loss Value = 0.21705818784236908\n",
      "Epoch 134 Validation Loss Value = 0.23354632868653252\n",
      "\n",
      "Epoch 135 Training Loss Value = 0.21513218224048614\n",
      "Epoch 135 Validation Loss Value = 0.23418373011407398\n",
      "\n",
      "Epoch 136 Training Loss Value = 0.21447269529104232\n",
      "Epoch 136 Validation Loss Value = 0.23410170466180832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = TranslationModel(device_train=device_fast)\n",
    "apply_weights(t)\n",
    "train_model(t,150,train_dataloader,valid_dataloader,optim.Adam(t.parameters(),lr=0.001),nn.CrossEntropyLoss(),device_train= device_fast,checkpoint_name='translation_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, max_len = 10,glove=glove):\n",
    "\n",
    "    model.eval()\n",
    "    nl_date = sentence.replace(\"\\'\",\"\").strip()\n",
    "    \n",
    "    nl_date = nl_date.lower()\n",
    "\n",
    "    if \"/\" in nl_date:\n",
    "        #number_list = list(nl_date)\n",
    "        #nl_date = \" \".join(number_list)\n",
    "        split_on_slash = nl_date.split(\"/\")\n",
    "        nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "        \n",
    "    embeddings = []\n",
    "    for word in nl_date.split(' '):\n",
    "        embeddings.append(glove[word])\n",
    "        #embeddings.append(torch.tensor(fasttext_model.get_word_vector(word)))\n",
    "\n",
    "\n",
    "    current_inp_length = len(embeddings)\n",
    "    inp_embeddings = torch.stack(embeddings)\n",
    "    inp_embeddings = inp_embeddings.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        encoder_outputs, hidden = model.encoder(inp_embeddings, [current_inp_length])\n",
    "        mask = model.create_mask([current_inp_length],max([current_inp_length]))\n",
    "        attentions = torch.zeros(max_len, 1, inp_embeddings.shape[1])\n",
    "        trg_indexes = []\n",
    "        for i in range(max_len):\n",
    "\n",
    "            if i==0:\n",
    "                trg_tensor = torch.LongTensor([output_vocab['<sos>']])\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                # input,hidden,encoder_outputs,encoder_length_mask\n",
    "                output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "\n",
    "            attentions[i] = attention\n",
    "            \n",
    "            pred_token = output.argmax(1).item()\n",
    "        \n",
    "            trg_indexes.append(pred_token)\n",
    "            trg_tensor = torch.LongTensor([pred_token])\n",
    "\n",
    "            if pred_token == output_vocab['<eos>']:\n",
    "                break\n",
    "    \n",
    "    trg_tokens = [output_index_to_word[i] for i in trg_indexes]\n",
    "    return trg_tokens, attentions\n",
    "    #print(trg_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmetrics(model,sentences,ground_truths):\n",
    "    exact_match_count = 0\n",
    "    per_word_matches = [0 for i in range(10)]\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        trg_tokens, attention_weights = translate_sentence(sentences[i],model)\n",
    "        #print(trg_tokens)\n",
    "        ground_truth_tokens = list(ground_truths[i])\n",
    "\n",
    "        exact_match = True\n",
    "        for i in range(len(ground_truth_tokens)):\n",
    "\n",
    "            if trg_tokens[i] == ground_truth_tokens[i]:\n",
    "                per_word_matches[i]+=1\n",
    "            else:\n",
    "                exact_match = False\n",
    "        \n",
    "        if exact_match:\n",
    "            exact_match_count+=1\n",
    "\n",
    "    \n",
    "    number = len(sentences)\n",
    "    per_output_accuracy = [ 0.0 for i in range(10)]\n",
    "    exact_match_accuracy = ((1.0*exact_match_count)/number)*100\n",
    "\n",
    "    for i in range(len(per_word_matches)):\n",
    "\n",
    "        per_output_accuracy[i] = ((1.0*per_word_matches[i]) / number) * 100\n",
    "\n",
    "    return exact_match_accuracy,per_output_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_test_dataset():\n",
    "    ground_truth = []\n",
    "    sentences = []\n",
    "    with open(\"./Assignment4aTestDataset.txt\",'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            nl_date , out_date = line.split(',')\n",
    "            nl_date = nl_date.replace(\"\\'\",\"\").strip()\n",
    "            out_date = out_date.replace(\"\\'\",\"\").strip()\n",
    "\n",
    "            if \"/\" in nl_date:\n",
    "                #number_list = list(nl_date)\n",
    "                #nl_date = \" \".join(number_list)\n",
    "                split_on_slash = nl_date.split(\"/\")\n",
    "                nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "            nl_date = nl_date.lower()\n",
    "\n",
    "            sentences.append(nl_date)\n",
    "            ground_truth.append(out_date)\n",
    "    return ground_truth,sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TranslationModel()\n",
    "t.load_state_dict(torch.load('./translation_model_2',map_location=device_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '0', '1', '9', '-', '0', '4', '-', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "output_tokens , attention = translate_sentence('21/04/2019',t.to(device_cpu))\n",
    "print(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94.89999999999999,\n",
       " [99.29,\n",
       "  96.89,\n",
       "  99.24,\n",
       "  97.91,\n",
       "  100.0,\n",
       "  99.71,\n",
       "  99.0,\n",
       "  100.0,\n",
       "  97.82,\n",
       "  97.24000000000001])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth,sentences = return_test_dataset()\n",
    "getmetrics(t,sentences,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heatmap(sentence, translation, attention):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(attention, cmap='viridis')\n",
    "\n",
    "    nl_date = sentence.replace(\"\\'\",\"\").strip()\n",
    "    nl_date = nl_date.lower()\n",
    "\n",
    "    if \"/\" in nl_date:\n",
    "        #number_list = list(nl_date)\n",
    "        #nl_date = \" \".join(number_list)\n",
    "        split_on_slash = nl_date.split(\"/\")\n",
    "        nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "    src = nl_date.split(\" \")\n",
    "    trg = list(translation)\n",
    "\n",
    "    ax.set_xticklabels(src, minor=False, rotation='vertical')\n",
    "    ax.set_yticklabels(trg, minor=False)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    # and the x-ticks on top\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticks(np.arange(attention.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(attention.shape[0]) + 0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.colorbar(heatmap)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/_xvm618541nc11hb7mv_kpj40000gn/T/ipykernel_57605/2566052727.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(src, minor=False, rotation='vertical')\n",
      "/var/folders/sm/_xvm618541nc11hb7mv_kpj40000gn/T/ipykernel_57605/2566052727.py:19: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(trg, minor=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_tokens , attention = translate_sentence('2016 20 Sunday May',t.to(device_cpu))\n",
    "plot_heatmap('2016 May 20 Sunday',''.join(output_tokens),attention.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/_xvm618541nc11hb7mv_kpj40000gn/T/ipykernel_57605/2566052727.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(src, minor=False, rotation='vertical')\n",
      "/var/folders/sm/_xvm618541nc11hb7mv_kpj40000gn/T/ipykernel_57605/2566052727.py:19: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(trg, minor=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_tokens , attention = translate_sentence('Saturday 29 February 2021',t.to(device_cpu))\n",
    "plot_heatmap('Saturday 29 February 2021',''.join(output_tokens),attention.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/_xvm618541nc11hb7mv_kpj40000gn/T/ipykernel_57605/2566052727.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(src, minor=False, rotation='vertical')\n",
      "/var/folders/sm/_xvm618541nc11hb7mv_kpj40000gn/T/ipykernel_57605/2566052727.py:19: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(trg, minor=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_tokens , attention = translate_sentence('29 February 2020',t.to(device_cpu))\n",
    "plot_heatmap('29 February 2020',''.join(output_tokens),attention.squeeze(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gymenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1b0110cf1cb03549be737c5657a86ea4daeeb81469a7991ed915d907f3e629c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
