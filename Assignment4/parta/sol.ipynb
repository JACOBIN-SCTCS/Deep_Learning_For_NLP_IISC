{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/depressedcoder/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler,DataLoader\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "TRAINABLE_EMBEDDINGS = False\n",
    "EMBED_DIM = 300 \n",
    "ENC_BIDIRECTIONAL = True\n",
    "ENC_BIDIRECTIONAL_FACTOR = 2 if ENC_BIDIRECTIONAL else 1\n",
    "ENC_HIDDEN_DIM = 256\n",
    "DEC_HIDDEN_DIM  = 256\n",
    "ENC_OUTPUT_DIM =  DEC_HIDDEN_DIM\n",
    "DEC_EMBED_DIM = 300\n",
    "NUM_EPOCHS = 300\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "device_fast = torch.device('cpu')\n",
    "\n",
    "if torch.has_mps:\n",
    "    device_fast = torch.device('mps')\n",
    "elif torch.has_cuda:\n",
    "    device_fast = torch.device('cuda')\n",
    "\n",
    "\n",
    "output_index_to_word = {}\n",
    "output_vocab = {}\n",
    "\n",
    "for i in range(0,10):\n",
    "    output_vocab[str(i)] = i\n",
    "    output_index_to_word[i] = str(i)\n",
    "\n",
    "output_vocab['-'] = 10\n",
    "output_index_to_word[10] = '-'\n",
    "output_vocab['<sos>'] = 11\n",
    "output_index_to_word[11] = '<sos>'\n",
    "output_vocab['<eos>'] = 12\n",
    "output_index_to_word[12] = '<eos>'\n",
    "\n",
    "glove = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_data(filename='./Assignment4aDataset.txt',glove=glove):\n",
    "    \n",
    "    f = open(filename,'r')\n",
    "    dataset = []\n",
    "    for line in f.readlines():       \n",
    "         \n",
    "        nl_date , out_date = line.split(',')\n",
    "        nl_date = nl_date.replace(\"\\'\",\"\").strip()\n",
    "        out_date = out_date.replace(\"\\'\",\"\").strip()\n",
    "\n",
    "        if \"/\" in nl_date:\n",
    "            #number_list = list(nl_date)\n",
    "            #nl_date = \" \".join(number_list)\n",
    "            split_on_slash = nl_date.split(\"/\")\n",
    "            nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "        nl_date = nl_date.lower()\n",
    "\n",
    "        embeddings = []\n",
    "        for word in nl_date.split(' '):\n",
    "            if word == '':\n",
    "                continue\n",
    "            if not TRAINABLE_EMBEDDINGS:\n",
    "                embeddings.append(glove[word])\n",
    "            else:\n",
    "                if word not in glove.stoi:\n",
    "                    embeddings.append(glove.stoi['unk'])\n",
    "                else:\n",
    "                    embeddings.append(glove.stoi[word])\n",
    "            \n",
    "            #embeddings.append(torch.tensor(fasttext_model.get_word_vector(word)))\n",
    "        current_inp_length = len(embeddings)\n",
    "        if not TRAINABLE_EMBEDDINGS:\n",
    "            embeddings = torch.stack(embeddings)\n",
    "        else:\n",
    "            embeddings = torch.tensor(embeddings)\n",
    "\n",
    "        target = []\n",
    "        target.append(output_vocab['<sos>'])\n",
    "\n",
    "        for character in list(out_date):\n",
    "            target.append(output_vocab[character])\n",
    "        \n",
    "        target.append(output_vocab['<eos>'])\n",
    "\n",
    "        dataset.append({'in' : embeddings,'in_length' : current_inp_length,'out' : target})\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_function(batch_data):\n",
    "    inputs = [b['in'] for b in batch_data]\n",
    "    in_lengths = [b['in_length'] for b in batch_data]\n",
    "    out = torch.tensor([b['out'] for b in batch_data])\n",
    "    inputs = pad_sequence(inputs,batch_first=True)\n",
    "    return {'src': inputs, 'src_length' : in_lengths, 'trg' : out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(get_training_data())\n",
    "\n",
    "train_idx,valid_idx = train_test_split(np.arange(len(train_dataset)), \n",
    "    test_size=0.2,\n",
    "    shuffle= True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_dataloader = DataLoader(train_dataset,BATCH_SIZE,sampler=train_sampler,collate_fn=collate_function)\n",
    "valid_dataloader = DataLoader(train_dataset,BATCH_SIZE,sampler=valid_sampler,collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,embed_dim = EMBED_DIM,enc_hidden_dim = ENC_HIDDEN_DIM,enc_output_dim = ENC_OUTPUT_DIM,NUM_LAYERS=1,enc_bidirectional=ENC_BIDIRECTIONAL,dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.embedding_layer = nn.Embedding(vocab_size,EMBED_DIM)\n",
    "        self.rnn = nn.GRU(embed_dim,enc_hidden_dim, num_layers = NUM_LAYERS ,batch_first= True ,bidirectional=enc_bidirectional)\n",
    "\n",
    "        if TRAINABLE_EMBEDDINGS:\n",
    "            self.embedding_layer = nn.Embedding.from_pretrained(glove.vectors,freeze=False)\n",
    "\n",
    "        # ENCODER_OUTPUT_DIM = DECODER_HIDDEN_SIZE\n",
    "        self.fc = nn.Linear(2*enc_hidden_dim,enc_output_dim) \n",
    "\n",
    "        self.fc_out = nn.Linear(enc_output_dim,1)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,inp,inp_len):\n",
    "        \n",
    "        if TRAINABLE_EMBEDDINGS:\n",
    "            embedded_input = self.embedding_layer(inp)\n",
    "        else:\n",
    "            embedded_input = inp   # [batch_size, input_seq_length, embed_dim ]\n",
    "        \n",
    "        packed_embedding = nn.utils.rnn.pack_padded_sequence(embedded_input,inp_len,batch_first=True,enforce_sorted=False)\n",
    "        packed_output , hidden = self.rnn(packed_embedding)  # hidden = [D*num_layers, batch_size , hidden_dim ]\n",
    "        outputs, _  = nn.utils.rnn.pad_packed_sequence(packed_output,batch_first=True)  # [batch_size, inp_seq_length, hidden_dim]\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1)))  # [batch_size, decoder_hidden_size]\n",
    "        return outputs,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear(enc_hidden_dim+dec_hidden_dim,dec_hidden_dim)\n",
    "        self.v = nn.Linear(dec_hidden_dim,1)\n",
    "\n",
    "    def forward(self,hidden,encoder_outputs, encoder_length_mask):\n",
    "        \n",
    "        # encoder_outputs = [batch_size,seq_length, enc_hidden_dim][2*ENCODER_HIDDEN_DIM or ENCODER_HIDDEN_DIM]\n",
    "        # hidden = [batch_size,  dec_hidden_dim]\n",
    "        # encoder_length_mask = [batch_size, seq_length]\n",
    "\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        h = hidden.unsqueeze(1).repeat(1,src_len,1)  # h = [batch_size,seq_length,dec_hidden_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((h,encoder_outputs),dim=2)))  #[batch_size,seq_length,dec_hidden_dim]\n",
    "        attention_scores = self.v(energy).squeeze(2)  # attention_scores = [batch_size , seq_length ]\n",
    "        attention_scores = attention_scores.masked_fill(encoder_length_mask==1, -1e10)   # Fill padding tokens with a lower value\n",
    "        attention_scores = F.softmax(attention_scores,dim=1)\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src_lengths,max_src_length):\n",
    "\n",
    "        src_mask = torch.zeros((len(src_lengths),max_src_length),dtype=torch.int64)\n",
    "        for i in range(len(src_lengths)):\n",
    "\n",
    "            src_mask[i,src_lengths[i]:] = 1\n",
    "        return src_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enc = Encoder(30,30,15,10)\n",
    "\n",
    "inp = torch.randn((3,20,30))\n",
    "inp_len = [20 for i in range(3)]\n",
    "outputs, hidden = enc(inp,inp_len)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,enc_hidden_dim,dec_hidden_dim,dec_output_dim,emb_dim):\n",
    "        \n",
    "        # enc_hidden_dim = 2*ENCODER_HIDDEN_DIM or ENCODER_HIDDEN_DIM\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.attention = Attention(enc_hidden_dim,dec_hidden_dim)\n",
    "        self.embedding_layer = nn.Embedding(vocab_size,emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hidden_dim + emb_dim,dec_hidden_dim,batch_first = True)\n",
    "\n",
    "        self.fc_out = nn.Linear(enc_hidden_dim + emb_dim + dec_hidden_dim , dec_output_dim)\n",
    "        #self.emb_dropout = nn.Dropout(0.3)\n",
    "        #self.fc_tilde = nn.Linear(enc_hidden_dim + emb_dim + dec_hidden_dim , dec_hidden_dim)\n",
    "        #self.max_out_layer = nn.MaxPool1d(kernel_size=2)\n",
    "        #self.W0 = nn.Linear(dec_hidden_dim>>1,emb_dim)\n",
    "        #self.prob_out = nn.Linear(emb_dim,vocab_size)\n",
    "        #self.prob_out.weight = self.embedding_layer.weight\n",
    "        \n",
    "\n",
    "    def forward(self,input,hidden,encoder_outputs,encoder_length_mask):\n",
    "            # encoder outputs =  batch_size , seq_len , encoder_output_dim\n",
    "            # hidden = batch_size , hidden_dim\n",
    "            # input = batch_size\n",
    "            \n",
    "            input = input.unsqueeze(0) # [1,batch_size]\n",
    "            embedded = self.embedding_layer(input)\n",
    "            #embedded = self.emb_dropout(self.embedding_layer(input)) # [1,batch_size,embed_dim]\n",
    "\n",
    "            embedded = embedded.permute(1,0,2) #[ batch_size, seq_length=1, embed_dim ]\n",
    "\n",
    "            attention_vector = self.attention(hidden,encoder_outputs,encoder_length_mask) # [ batch_size , seq_length ]\n",
    "            attention_vector = attention_vector.unsqueeze(1) # [batch_size , 1 , seq_length ]\n",
    "\n",
    "            weighted = torch.bmm(attention_vector,encoder_outputs) # [ batch_size, 1, encoder_output_dim]\n",
    "            #weighted = weighted.permute(1,0,2) #[1 , batch_size , encoder_output_dim]\n",
    "\n",
    "\n",
    "            rnn_input = torch.cat((embedded,weighted),dim=2) #[batch_size, seq_length=1, encoder + decoder]\n",
    "\n",
    "            out,h = self.rnn(rnn_input,hidden.unsqueeze(0)) # consider only a single layer (1.) so unsqueeze(0)\n",
    "\n",
    "            # out = [batch_size, seq_length = 1, decoder_hidden_out (bidirectional)]\n",
    "            # hidden = [D*num_layers,batch_size, decoder_hidden_out]\n",
    "\n",
    "\n",
    "            embedded = embedded.squeeze(1)  # [batch_size,embed_dim]\n",
    "            out = out.squeeze(1)    #[batch_size, decoder_hidden_out] # Have to change if the number of layers is changed to more than 1\n",
    "            weighted = weighted.squeeze(1)  # [batch_size,encoder_output_dim] \n",
    "            prediction = self.fc_out(torch.cat([embedded,out,weighted],dim=1)) #[batch_size, decoder_output_dim]\n",
    "            \n",
    "            \n",
    "            #prediction = F.softmax(self.fc_out(torch.cat([embedded,out,weighted],dim=1)),dim=1) #[batch_size, decoder_output_dim]\n",
    "            #t_tilde =  self.fc_tilde(torch.cat([embedded,out,weighted],dim=1)) # [batch_size, decoder_hidden_dim]\n",
    "            #t_tilde = self.max_out_layer(t_tilde.unsqueeze(1)) #[batch_size,1,decoder_hidden_dim/2]\n",
    "            #t_tilde = t_tilde.squeeze(1)\n",
    "\n",
    "            #inter_step  = self.W0(t_tilde) # [ batch_size , dec_embeddim]\n",
    "            #prediction = self.prob_out(inter_step) #[  batch_size , vocab_size]\n",
    "            #prediction = F.softmax(prediction,dim=1)\n",
    "            return prediction, h.squeeze(0), attention_vector # Reduce the number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                input_embed_dim = EMBED_DIM,\n",
    "                encoder_hidden_dim = ENC_HIDDEN_DIM,\n",
    "                encoder_hidden_output = ENC_OUTPUT_DIM,\n",
    "                enc_num_layers = 1,\n",
    "                enc_bidirectional = ENC_BIDIRECTIONAL,\n",
    "\n",
    "                dec_vocab_size = len(output_vocab),\n",
    "                dec_embed_dim = DEC_EMBED_DIM,\n",
    "                dec_hidden_dim  =DEC_HIDDEN_DIM,\n",
    "                device_train = device_cpu\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_embed_dim,encoder_hidden_dim,encoder_hidden_output,enc_num_layers,enc_bidirectional=enc_bidirectional)\n",
    "        enc_bidirectional_factor = 2 if enc_bidirectional else 1\n",
    "        self.decoder = Decoder(dec_vocab_size,enc_bidirectional_factor*encoder_hidden_dim,dec_hidden_dim=dec_hidden_dim,dec_output_dim=dec_vocab_size,emb_dim=dec_embed_dim)\n",
    "        self.device_train = device_train\n",
    "\n",
    "\n",
    "    def create_mask(self, src_lengths,max_src_length):\n",
    "\n",
    "        src_mask = torch.zeros((len(src_lengths),max_src_length),dtype=torch.int64)\n",
    "        for i in range(len(src_lengths)):\n",
    "\n",
    "            src_mask[i,src_lengths[i]:] = 1\n",
    "        return src_mask\n",
    "        \n",
    "    def forward(self,source,source_len,target,teacher_forcing_ratio = 0.0):\n",
    "        #   source = [batch_size, max_src_len]\n",
    "        #   source_len = [length of sentence in the batch]\n",
    "        #   target = [batch_size,traget_length]\n",
    "        #   teacher_forcing_ratio = probability to use teacher forcinbg\n",
    "\n",
    "        batch_size = source.shape[0]\n",
    "        target_length = target.shape[1]\n",
    "        target_vocab_size = self.decoder.vocab_size\n",
    "        outputs= torch.zeros(batch_size,target_length,target_vocab_size).to(self.device_train)\n",
    "        encoder_outputs , hidden = self.encoder(source,source_len)\n",
    "\n",
    "        inp = target[:,0]        \n",
    "        enc_mask = self.create_mask(source_len,int(encoder_outputs.shape[1]))\n",
    "        enc_mask = enc_mask.to(self.device_train)\n",
    "        for t in range(1,target_length):\n",
    "            decoder_output, hidden, attention_vector =  self.decoder(inp,hidden,encoder_outputs,enc_mask)\n",
    "\n",
    "            outputs[:,t,:] = decoder_output # batch_size, vocab_size\n",
    "            teacher_force = random.random() < teacher_forcing_ratio \n",
    "\n",
    "            top1 = decoder_output.argmax(1)\n",
    "\n",
    "            inp = target[:,t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weights(model : TranslationModel):\n",
    "    \n",
    "    for name,param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data,mean=0,std=0.01)\n",
    "            #nn.init.xavier_uniform_(param.data)\n",
    "        else:\n",
    "            nn.init.constant_(param.data,0)\n",
    "    \n",
    "    \n",
    "    #nn.init.xavier_uniform_(model.encoder.fc_out.weight)\n",
    "    #nn.init.xavier_uniform_(model.decoder.attention.attn.weight)\n",
    "\n",
    "    nn.init.normal_(model.decoder.attention.attn.weight, mean=0, std=0.001)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = TranslationModel()\n",
    "apply_weights(t)\n",
    "batch_data = next(iter(train_dataloader))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=output_vocab['<eos>'])\n",
    "optimizer = optim.Adam(t.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "model_output = t(batch_data['src'],batch_data['src_length'],batch_data['trg'])\n",
    "\n",
    "\n",
    "model_out_reshaped = model_output[1:].view(-1,model_output.shape[-1])\n",
    "reshaped_target = batch_data['trg'][1:].view(-1)\n",
    "loss_value = criterion(model_out_reshaped,reshaped_target)\n",
    "loss_value.backward()\n",
    "nn.utils.clip_grad_norm_(t.parameters(),5)\n",
    "optimizer.step()\n",
    "print(loss_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import  datetime\n",
    "\n",
    "import os\n",
    "\n",
    "def train_model(model,num_epochs,train_loader,valid_loader,optimizer,criterion,checkpoint_name='translation_model.pth',device_train = device_cpu):\n",
    "    \n",
    "    current_datetime = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    tensorboard_name =  checkpoint_name + current_datetime\n",
    "    writer = SummaryWriter('runs/' + tensorboard_name)\n",
    "\n",
    "    best_validation_loss = 1000.0\n",
    "    model = model.to(device_train)\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        model.train()\n",
    "        for i,batch in enumerate(train_loader):\n",
    "\n",
    "            source, source_length, target = batch['src'], batch['src_length'], batch['trg']\n",
    "\n",
    "            source = source.to(device_train)\n",
    "            target = target.to(device_train)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # model_output = [batch_size, output_seq_length,vocab_size]\n",
    "            model_output  = model(source,source_length,target)\n",
    "\n",
    "\n",
    "            source = source.to(device_cpu)\n",
    "            target = target.to(device_cpu)\n",
    "            model_output = model_output.to(device_cpu)\n",
    "            \n",
    "            model_out_reshaped = model_output[1:].view(-1,model_output.shape[-1]) \n",
    "            #print(model_out_reshaped.shape)\n",
    "            reshaped_target = target[1:].view(-1)\n",
    "            #print(reshaped_target.shape)\n",
    "\n",
    "            loss_value = criterion(model_out_reshaped,reshaped_target)\n",
    "            loss_value.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),5)\n",
    "\n",
    "            optimizer.step()\n",
    "            training_loss += loss_value.item()\n",
    "        \n",
    "        print(\"Epoch \" + str(e) + \" Training Loss Value = \" + str(training_loss/len(train_loader)))\n",
    "        writer.add_scalars('Train/Loss vs Epoch',{'train' :training_loss/len(train_loader)},e)\n",
    "\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i, batch in enumerate(valid_loader):\n",
    "                source, source_length, target = batch['src'], batch['src_length'], batch['trg']\n",
    "\n",
    "                source = source.to(device_train)\n",
    "                target = target.to(device_train)\n",
    "\n",
    "                model_output  = model(source,source_length,target,0)\n",
    "\n",
    "\n",
    "                source = source.to(device_cpu)\n",
    "                target = target.to(device_cpu)\n",
    "                model_output = model_output.to(device_cpu)\n",
    "                \n",
    "                model_out_reshaped = model_output[1:].view(-1,model_output.shape[-1])\n",
    "                reshaped_target = target[1:].view(-1)\n",
    "                loss_value = criterion(model_out_reshaped,reshaped_target)\n",
    "\n",
    "                validation_loss += loss_value.item()\n",
    "        averaged_validation_loss = validation_loss/len(valid_loader)\n",
    "        writer.add_scalars('Train/Loss vs Epoch',{'valid' :averaged_validation_loss},e)\n",
    "\n",
    "        print(\"Epoch \" + str(e) + \" Validation Loss Value = \" + str(averaged_validation_loss))\n",
    "        print(\"\")\n",
    "        if (averaged_validation_loss <= best_validation_loss):\n",
    "            best_validation_loss = averaged_validation_loss\n",
    "            torch.save(model.state_dict(),checkpoint_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss Value = 1.1530088188648224\n",
      "Epoch 0 Validation Loss Value = 0.5815817988108075\n",
      "\n",
      "Epoch 1 Training Loss Value = 0.45360297453403475\n",
      "Epoch 1 Validation Loss Value = 0.3678397962025234\n",
      "\n",
      "Epoch 2 Training Loss Value = 0.3087123005390167\n",
      "Epoch 2 Validation Loss Value = 0.2678949269983504\n",
      "\n",
      "Epoch 3 Training Loss Value = 0.24842149513959885\n",
      "Epoch 3 Validation Loss Value = 0.24005483611235542\n",
      "\n",
      "Epoch 4 Training Loss Value = 0.2338920983672142\n",
      "Epoch 4 Validation Loss Value = 0.23280652908105698\n",
      "\n",
      "Epoch 5 Training Loss Value = 0.4828983426094055\n",
      "Epoch 5 Validation Loss Value = 0.24144677273810855\n",
      "\n",
      "Epoch 6 Training Loss Value = 0.23431067776679992\n",
      "Epoch 6 Validation Loss Value = 0.23017132471478174\n",
      "\n",
      "Epoch 7 Training Loss Value = 0.22913124603033067\n",
      "Epoch 7 Validation Loss Value = 0.22751961388285197\n",
      "\n",
      "Epoch 8 Training Loss Value = 0.227423486828804\n",
      "Epoch 8 Validation Loss Value = 0.23006540584185767\n",
      "\n",
      "Epoch 9 Training Loss Value = 0.22567995297908783\n",
      "Epoch 9 Validation Loss Value = 0.22706467977591924\n",
      "\n",
      "Epoch 10 Training Loss Value = 0.2244789828658104\n",
      "Epoch 10 Validation Loss Value = 0.22476275951143296\n",
      "\n",
      "Epoch 11 Training Loss Value = 0.22525205624103545\n",
      "Epoch 11 Validation Loss Value = 0.25171923968527055\n",
      "\n",
      "Epoch 12 Training Loss Value = 0.22753960579633714\n",
      "Epoch 12 Validation Loss Value = 0.2253935838502551\n",
      "\n",
      "Epoch 13 Training Loss Value = 0.2237338427901268\n",
      "Epoch 13 Validation Loss Value = 0.22375233849835774\n",
      "\n",
      "Epoch 14 Training Loss Value = 0.22265186285972596\n",
      "Epoch 14 Validation Loss Value = 0.2240070371873795\n",
      "\n",
      "Epoch 15 Training Loss Value = 0.22388419365882872\n",
      "Epoch 15 Validation Loss Value = 0.23135374675667475\n",
      "\n",
      "Epoch 16 Training Loss Value = 0.22578930538892747\n",
      "Epoch 16 Validation Loss Value = 0.22342809277867515\n",
      "\n",
      "Epoch 17 Training Loss Value = 0.22205783253908157\n",
      "Epoch 17 Validation Loss Value = 0.22338742750977714\n",
      "\n",
      "Epoch 18 Training Loss Value = 0.22219956433773042\n",
      "Epoch 18 Validation Loss Value = 0.2269720451699363\n",
      "\n",
      "Epoch 19 Training Loss Value = 0.22945166254043578\n",
      "Epoch 19 Validation Loss Value = 0.26891454368356676\n",
      "\n",
      "Epoch 20 Training Loss Value = 0.22572753804922105\n",
      "Epoch 20 Validation Loss Value = 0.22357898501176682\n",
      "\n",
      "Epoch 21 Training Loss Value = 0.2214931934475899\n",
      "Epoch 21 Validation Loss Value = 0.22355618032198105\n",
      "\n",
      "Epoch 22 Training Loss Value = 0.22158812499046326\n",
      "Epoch 22 Validation Loss Value = 0.22382882828750308\n",
      "\n",
      "Epoch 23 Training Loss Value = 0.22162218487262725\n",
      "Epoch 23 Validation Loss Value = 0.22341898698655385\n",
      "\n",
      "Epoch 24 Training Loss Value = 0.22158184683322907\n",
      "Epoch 24 Validation Loss Value = 0.24272995714157347\n",
      "\n",
      "Epoch 25 Training Loss Value = 0.22477969807386397\n",
      "Epoch 25 Validation Loss Value = 0.2236843305447745\n",
      "\n",
      "Epoch 26 Training Loss Value = 0.22145918726921082\n",
      "Epoch 26 Validation Loss Value = 0.22436554351496318\n",
      "\n",
      "Epoch 27 Training Loss Value = 0.221641597867012\n",
      "Epoch 27 Validation Loss Value = 0.2254484064049191\n",
      "\n",
      "Epoch 28 Training Loss Value = 0.22065082496404648\n",
      "Epoch 28 Validation Loss Value = 0.22440029893602645\n",
      "\n",
      "Epoch 29 Training Loss Value = 0.2220360227227211\n",
      "Epoch 29 Validation Loss Value = 0.22756707029683249\n",
      "\n",
      "Epoch 30 Training Loss Value = 0.22254507213830949\n",
      "Epoch 30 Validation Loss Value = 0.22371763014604176\n",
      "\n",
      "Epoch 31 Training Loss Value = 0.22075142335891723\n",
      "Epoch 31 Validation Loss Value = 0.22346408002906376\n",
      "\n",
      "Epoch 32 Training Loss Value = 0.2202568838596344\n",
      "Epoch 32 Validation Loss Value = 0.2236203390454489\n",
      "\n",
      "Epoch 33 Training Loss Value = 0.21986490505933762\n",
      "Epoch 33 Validation Loss Value = 0.2441162530864988\n",
      "\n",
      "Epoch 34 Training Loss Value = 0.22532980197668076\n",
      "Epoch 34 Validation Loss Value = 0.22564991173290072\n",
      "\n",
      "Epoch 35 Training Loss Value = 0.22014600360393524\n",
      "Epoch 35 Validation Loss Value = 0.22445291162483275\n",
      "\n",
      "Epoch 36 Training Loss Value = 0.21982970881462097\n",
      "Epoch 36 Validation Loss Value = 0.22487101053434705\n",
      "\n",
      "Epoch 37 Training Loss Value = 0.2190016034245491\n",
      "Epoch 37 Validation Loss Value = 0.22472194262913295\n",
      "\n",
      "Epoch 38 Training Loss Value = 0.218897745013237\n",
      "Epoch 38 Validation Loss Value = 0.22556453801336743\n",
      "\n",
      "Epoch 39 Training Loss Value = 0.21930091059207915\n",
      "Epoch 39 Validation Loss Value = 0.22617521479962363\n",
      "\n",
      "Epoch 40 Training Loss Value = 0.22424473464488984\n",
      "Epoch 40 Validation Loss Value = 0.22565822303295135\n",
      "\n",
      "Epoch 41 Training Loss Value = 0.22112418282032012\n",
      "Epoch 41 Validation Loss Value = 0.22590092344889565\n",
      "\n",
      "Epoch 42 Training Loss Value = 0.21920551145076753\n",
      "Epoch 42 Validation Loss Value = 0.22630804540619018\n",
      "\n",
      "Epoch 43 Training Loss Value = 0.21814736193418502\n",
      "Epoch 43 Validation Loss Value = 0.22582354526671153\n",
      "\n",
      "Epoch 44 Training Loss Value = 0.2175997338294983\n",
      "Epoch 44 Validation Loss Value = 0.22552177924958486\n",
      "\n",
      "Epoch 45 Training Loss Value = 0.21778397107124328\n",
      "Epoch 45 Validation Loss Value = 0.22866814169618818\n",
      "\n",
      "Epoch 46 Training Loss Value = 0.21823650938272476\n",
      "Epoch 46 Validation Loss Value = 0.22779316537910038\n",
      "\n",
      "Epoch 47 Training Loss Value = 0.21759165227413177\n",
      "Epoch 47 Validation Loss Value = 0.22795533282416208\n",
      "\n",
      "Epoch 48 Training Loss Value = 0.21698029780387879\n",
      "Epoch 48 Validation Loss Value = 0.22837763575334397\n",
      "\n",
      "Epoch 49 Training Loss Value = 0.21668169897794723\n",
      "Epoch 49 Validation Loss Value = 0.22737642578662387\n",
      "\n",
      "Epoch 50 Training Loss Value = 0.2231400185227394\n",
      "Epoch 50 Validation Loss Value = 0.22975098022392818\n",
      "\n",
      "Epoch 51 Training Loss Value = 0.2180986869931221\n",
      "Epoch 51 Validation Loss Value = 0.22723224167785946\n",
      "\n",
      "Epoch 52 Training Loss Value = 0.21597330772876738\n",
      "Epoch 52 Validation Loss Value = 0.22798363651548112\n",
      "\n",
      "Epoch 53 Training Loss Value = 0.21543696761131287\n",
      "Epoch 53 Validation Loss Value = 0.22972423855274443\n",
      "\n",
      "Epoch 54 Training Loss Value = 0.2167821597456932\n",
      "Epoch 54 Validation Loss Value = 0.22811177656764076\n",
      "\n",
      "Epoch 55 Training Loss Value = 0.21526587557792665\n",
      "Epoch 55 Validation Loss Value = 0.22920877048893581\n",
      "\n",
      "Epoch 56 Training Loss Value = 0.21522199237346648\n",
      "Epoch 56 Validation Loss Value = 0.22938088173904117\n",
      "\n",
      "Epoch 57 Training Loss Value = 0.2166156668663025\n",
      "Epoch 57 Validation Loss Value = 0.22860451326483772\n",
      "\n",
      "Epoch 58 Training Loss Value = 0.2190148389339447\n",
      "Epoch 58 Validation Loss Value = 0.23149793748817746\n",
      "\n",
      "Epoch 59 Training Loss Value = 0.2159022440314293\n",
      "Epoch 59 Validation Loss Value = 0.2301947661335506\n",
      "\n",
      "Epoch 60 Training Loss Value = 0.21691797691583634\n",
      "Epoch 60 Validation Loss Value = 0.2298349260337769\n",
      "\n",
      "Epoch 61 Training Loss Value = 0.2163553414940834\n",
      "Epoch 61 Validation Loss Value = 0.22976283894644844\n",
      "\n",
      "Epoch 62 Training Loss Value = 0.21563167387247087\n",
      "Epoch 62 Validation Loss Value = 0.22944751925884732\n",
      "\n",
      "Epoch 63 Training Loss Value = 0.21470939528942107\n",
      "Epoch 63 Validation Loss Value = 0.2301704753485937\n",
      "\n",
      "Epoch 64 Training Loss Value = 0.214480639398098\n",
      "Epoch 64 Validation Loss Value = 0.23097776420532712\n",
      "\n",
      "Epoch 65 Training Loss Value = 0.21436867731809617\n",
      "Epoch 65 Validation Loss Value = 0.23129066446470836\n",
      "\n",
      "Epoch 66 Training Loss Value = 0.21429170554876328\n",
      "Epoch 66 Validation Loss Value = 0.23136012492671845\n",
      "\n",
      "Epoch 67 Training Loss Value = 0.21434348142147064\n",
      "Epoch 67 Validation Loss Value = 0.23149757442020236\n",
      "\n",
      "Epoch 68 Training Loss Value = 0.22513617712259293\n",
      "Epoch 68 Validation Loss Value = 0.2295759069541144\n",
      "\n",
      "Epoch 69 Training Loss Value = 0.21641955482959746\n",
      "Epoch 69 Validation Loss Value = 0.2314324128249335\n",
      "\n",
      "Epoch 70 Training Loss Value = 0.21530942118167878\n",
      "Epoch 70 Validation Loss Value = 0.23066862542477864\n",
      "\n",
      "Epoch 71 Training Loss Value = 0.21454205137491225\n",
      "Epoch 71 Validation Loss Value = 0.23171589393464345\n",
      "\n",
      "Epoch 72 Training Loss Value = 0.21425840640068053\n",
      "Epoch 72 Validation Loss Value = 0.23152034055619014\n",
      "\n",
      "Epoch 73 Training Loss Value = 0.2141589041352272\n",
      "Epoch 73 Validation Loss Value = 0.23203964673337482\n",
      "\n",
      "Epoch 74 Training Loss Value = 0.2140803498029709\n",
      "Epoch 74 Validation Loss Value = 0.2322751707027829\n",
      "\n",
      "Epoch 75 Training Loss Value = 0.21412203824520112\n",
      "Epoch 75 Validation Loss Value = 0.23234926779118795\n",
      "\n",
      "Epoch 76 Training Loss Value = 0.21406013065576554\n",
      "Epoch 76 Validation Loss Value = 0.23385968213043515\n",
      "\n",
      "Epoch 77 Training Loss Value = 0.214142808675766\n",
      "Epoch 77 Validation Loss Value = 0.23309215217355697\n",
      "\n",
      "Epoch 78 Training Loss Value = 0.21414024299383164\n",
      "Epoch 78 Validation Loss Value = 0.23305751146778228\n",
      "\n",
      "Epoch 79 Training Loss Value = 0.21418014132976532\n",
      "Epoch 79 Validation Loss Value = 0.23335176375177172\n",
      "\n",
      "Epoch 80 Training Loss Value = 0.22504703682661056\n",
      "Epoch 80 Validation Loss Value = 0.23153102823666163\n",
      "\n",
      "Epoch 81 Training Loss Value = 0.2189675897359848\n",
      "Epoch 81 Validation Loss Value = 0.23007643624903665\n",
      "\n",
      "Epoch 82 Training Loss Value = 0.21566936612129212\n",
      "Epoch 82 Validation Loss Value = 0.23068560305095853\n",
      "\n",
      "Epoch 83 Training Loss Value = 0.21470764684677124\n",
      "Epoch 83 Validation Loss Value = 0.23122637659784348\n",
      "\n",
      "Epoch 84 Training Loss Value = 0.2142454156279564\n",
      "Epoch 84 Validation Loss Value = 0.23261795204783242\n",
      "\n",
      "Epoch 85 Training Loss Value = 0.21409293305873872\n",
      "Epoch 85 Validation Loss Value = 0.2328952139332181\n",
      "\n",
      "Epoch 86 Training Loss Value = 0.2140023558139801\n",
      "Epoch 86 Validation Loss Value = 0.2328249393474488\n",
      "\n",
      "Epoch 87 Training Loss Value = 0.21408427602052688\n",
      "Epoch 87 Validation Loss Value = 0.23412018115558322\n",
      "\n",
      "Epoch 88 Training Loss Value = 0.21410535645484924\n",
      "Epoch 88 Validation Loss Value = 0.23366652027009024\n",
      "\n",
      "Epoch 89 Training Loss Value = 0.21409008687734604\n",
      "Epoch 89 Validation Loss Value = 0.23393466288135165\n",
      "\n",
      "Epoch 90 Training Loss Value = 0.214283559858799\n",
      "Epoch 90 Validation Loss Value = 0.23425072904617067\n",
      "\n",
      "Epoch 91 Training Loss Value = 0.2250559656023979\n",
      "Epoch 91 Validation Loss Value = 0.23272577046401918\n",
      "\n",
      "Epoch 92 Training Loss Value = 0.2157222065925598\n",
      "Epoch 92 Validation Loss Value = 0.23217472268475425\n",
      "\n",
      "Epoch 93 Training Loss Value = 0.21461777907609939\n",
      "Epoch 93 Validation Loss Value = 0.23326151711600168\n",
      "\n",
      "Epoch 94 Training Loss Value = 0.21423870342969895\n",
      "Epoch 94 Validation Loss Value = 0.2329171761160805\n",
      "\n",
      "Epoch 95 Training Loss Value = 0.21406093436479567\n",
      "Epoch 95 Validation Loss Value = 0.23320725536535655\n",
      "\n",
      "Epoch 96 Training Loss Value = 0.2140482760667801\n",
      "Epoch 96 Validation Loss Value = 0.23287512078171685\n",
      "\n",
      "Epoch 97 Training Loss Value = 0.21400169050693513\n",
      "Epoch 97 Validation Loss Value = 0.23332663187904965\n",
      "\n",
      "Epoch 98 Training Loss Value = 0.21400957703590393\n",
      "Epoch 98 Validation Loss Value = 0.23436272759286184\n",
      "\n",
      "Epoch 99 Training Loss Value = 0.21404813778400422\n",
      "Epoch 99 Validation Loss Value = 0.23394370268261622\n",
      "\n",
      "Epoch 100 Training Loss Value = 0.2140963824391365\n",
      "Epoch 100 Validation Loss Value = 0.23351914376493485\n",
      "\n",
      "Epoch 101 Training Loss Value = 0.2162365572452545\n",
      "Epoch 101 Validation Loss Value = 0.24021061403410776\n",
      "\n",
      "Epoch 102 Training Loss Value = 0.22410773473978043\n",
      "Epoch 102 Validation Loss Value = 0.23247247248414962\n",
      "\n",
      "Epoch 103 Training Loss Value = 0.21645767080783845\n",
      "Epoch 103 Validation Loss Value = 0.2320970774643005\n",
      "\n",
      "Epoch 104 Training Loss Value = 0.21483299994468688\n",
      "Epoch 104 Validation Loss Value = 0.23250415542769054\n",
      "\n",
      "Epoch 105 Training Loss Value = 0.2142940073609352\n",
      "Epoch 105 Validation Loss Value = 0.23344942359697252\n",
      "\n",
      "Epoch 106 Training Loss Value = 0.21408895283937454\n",
      "Epoch 106 Validation Loss Value = 0.2341386517361989\n",
      "\n",
      "Epoch 107 Training Loss Value = 0.2140261577963829\n",
      "Epoch 107 Validation Loss Value = 0.23346716378416335\n",
      "\n",
      "Epoch 108 Training Loss Value = 0.2140146369934082\n",
      "Epoch 108 Validation Loss Value = 0.23350950980943347\n",
      "\n",
      "Epoch 109 Training Loss Value = 0.21401855063438416\n",
      "Epoch 109 Validation Loss Value = 0.2338223121468983\n",
      "\n",
      "Epoch 110 Training Loss Value = 0.2139838873744011\n",
      "Epoch 110 Validation Loss Value = 0.23404923152355922\n",
      "\n",
      "Epoch 111 Training Loss Value = 0.21401056265830995\n",
      "Epoch 111 Validation Loss Value = 0.2345931844578849\n",
      "\n",
      "Epoch 112 Training Loss Value = 0.2140106982588768\n",
      "Epoch 112 Validation Loss Value = 0.23595399941716874\n",
      "\n",
      "Epoch 113 Training Loss Value = 0.22087404960393905\n",
      "Epoch 113 Validation Loss Value = 0.23618099684753116\n",
      "\n",
      "Epoch 114 Training Loss Value = 0.22069137173891068\n",
      "Epoch 114 Validation Loss Value = 0.2326644476917055\n",
      "\n",
      "Epoch 115 Training Loss Value = 0.21795697885751725\n",
      "Epoch 115 Validation Loss Value = 0.2320607633344711\n",
      "\n",
      "Epoch 116 Training Loss Value = 0.21493527805805207\n",
      "Epoch 116 Validation Loss Value = 0.23268470712124356\n",
      "\n",
      "Epoch 117 Training Loss Value = 0.21426956462860108\n",
      "Epoch 117 Validation Loss Value = 0.23326601608405037\n",
      "\n",
      "Epoch 118 Training Loss Value = 0.21407191491127014\n",
      "Epoch 118 Validation Loss Value = 0.23360856918115463\n",
      "\n",
      "Epoch 119 Training Loss Value = 0.21400632512569429\n",
      "Epoch 119 Validation Loss Value = 0.2337511650153569\n",
      "\n",
      "Epoch 120 Training Loss Value = 0.21397652167081832\n",
      "Epoch 120 Validation Loss Value = 0.23382334032702068\n",
      "\n",
      "Epoch 121 Training Loss Value = 0.2139777107834816\n",
      "Epoch 121 Validation Loss Value = 0.23354198535283408\n",
      "\n",
      "Epoch 122 Training Loss Value = 0.21398809140920638\n",
      "Epoch 122 Validation Loss Value = 0.23495857796025654\n",
      "\n",
      "Epoch 123 Training Loss Value = 0.2145059126019478\n",
      "Epoch 123 Validation Loss Value = 0.23566486248894344\n",
      "\n",
      "Epoch 124 Training Loss Value = 0.22152128112316133\n",
      "Epoch 124 Validation Loss Value = 0.23532679511441124\n",
      "\n",
      "Epoch 125 Training Loss Value = 0.21636374950408935\n",
      "Epoch 125 Validation Loss Value = 0.23449850271618555\n",
      "\n",
      "Epoch 126 Training Loss Value = 0.21488291019201278\n",
      "Epoch 126 Validation Loss Value = 0.23374176025390625\n",
      "\n",
      "Epoch 127 Training Loss Value = 0.2142107101082802\n",
      "Epoch 127 Validation Loss Value = 0.23479631850643765\n",
      "\n",
      "Epoch 128 Training Loss Value = 0.21410453021526338\n",
      "Epoch 128 Validation Loss Value = 0.2352856175293998\n",
      "\n",
      "Epoch 129 Training Loss Value = 0.21404275685548782\n",
      "Epoch 129 Validation Loss Value = 0.2342982982832288\n",
      "\n",
      "Epoch 130 Training Loss Value = 0.2140190235376358\n",
      "Epoch 130 Validation Loss Value = 0.235684905733381\n",
      "\n",
      "Epoch 131 Training Loss Value = 0.21398870331048966\n",
      "Epoch 131 Validation Loss Value = 0.2351304188607231\n",
      "\n",
      "Epoch 132 Training Loss Value = 0.21399526846408845\n",
      "Epoch 132 Validation Loss Value = 0.23598532000231365\n",
      "\n",
      "Epoch 133 Training Loss Value = 0.21401688653230666\n",
      "Epoch 133 Validation Loss Value = 0.23509116116024198\n",
      "\n",
      "Epoch 134 Training Loss Value = 0.2139745472073555\n",
      "Epoch 134 Validation Loss Value = 0.23628380256039755\n",
      "\n",
      "Epoch 135 Training Loss Value = 0.21400120234489442\n",
      "Epoch 135 Validation Loss Value = 0.23558457597853646\n",
      "\n",
      "Epoch 136 Training Loss Value = 0.21770716643333435\n",
      "Epoch 136 Validation Loss Value = 0.24747630244209654\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2848351/2896689212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_fast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mapply_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdevice_fast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'translation_model_11'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2848351/504630096.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, train_loader, valid_loader, optimizer, criterion, checkpoint_name, device_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out_reshaped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreshaped_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/depressedcoder/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/depressedcoder/anaconda3/envs/pytorchenv/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = TranslationModel(device_train=device_fast)\n",
    "apply_weights(t)\n",
    "train_model(t,750,train_dataloader,valid_dataloader,optim.Adam(t.parameters(),lr=0.001),nn.CrossEntropyLoss(),device_train= device_fast,checkpoint_name='translation_model_11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, max_len = 10,glove=glove):\n",
    "\n",
    "    model.eval()\n",
    "    nl_date = sentence.replace(\"\\'\",\"\").strip()\n",
    "    \n",
    "    nl_date = nl_date.lower()\n",
    "\n",
    "    if \"/\" in nl_date:\n",
    "        #number_list = list(nl_date)\n",
    "        #nl_date = \" \".join(number_list)\n",
    "        split_on_slash = nl_date.split(\"/\")\n",
    "        nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "        \n",
    "    embeddings = []\n",
    "    for word in nl_date.split(' '):\n",
    "        if not TRAINABLE_EMBEDDINGS:\n",
    "            embeddings.append(glove[word])\n",
    "        else:\n",
    "            if word not in glove.stoi:\n",
    "                embeddings.append(glove.stoi['unk'])\n",
    "            else:\n",
    "                embeddings.append(glove.stoi[word])\n",
    "        #embeddings.append(torch.tensor(fasttext_model.get_word_vector(word)))\n",
    "\n",
    "\n",
    "    current_inp_length = len(embeddings)\n",
    "    if not TRAINABLE_EMBEDDINGS:\n",
    "        inp_embeddings = torch.stack(embeddings)\n",
    "    else:\n",
    "        inp_embeddings = torch.tensor(embeddings)\n",
    "    inp_embeddings = inp_embeddings.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        encoder_outputs, hidden = model.encoder(inp_embeddings, [current_inp_length])\n",
    "        mask = model.create_mask([current_inp_length],max([current_inp_length]))\n",
    "        attentions = torch.zeros(max_len, 1, inp_embeddings.shape[1])\n",
    "        trg_indexes = []\n",
    "        for i in range(max_len):\n",
    "\n",
    "            if i==0:\n",
    "                trg_tensor = torch.LongTensor([output_vocab['<sos>']])\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                # input,hidden,encoder_outputs,encoder_length_mask\n",
    "                output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "\n",
    "            attentions[i] = attention\n",
    "            \n",
    "            pred_token = output.argmax(1).item()\n",
    "        \n",
    "            trg_indexes.append(pred_token)\n",
    "            trg_tensor = torch.LongTensor([pred_token])\n",
    "\n",
    "            if pred_token == output_vocab['<eos>']:\n",
    "                break\n",
    "    \n",
    "    trg_tokens = [output_index_to_word[i] for i in trg_indexes]\n",
    "    return trg_tokens, attentions\n",
    "    #print(trg_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmetrics(model,sentences,ground_truths):\n",
    "    exact_match_count = 0\n",
    "    per_word_matches = [0 for i in range(10)]\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        trg_tokens, attention_weights = translate_sentence(sentences[i],model)\n",
    "        ground_truth_tokens = list(ground_truths[i])\n",
    "\n",
    "        exact_match = True\n",
    "        for i in range(len(ground_truth_tokens)):\n",
    "\n",
    "            if trg_tokens[i] == ground_truth_tokens[i]:\n",
    "                per_word_matches[i]+=1\n",
    "            else:\n",
    "                exact_match = False\n",
    "        \n",
    "        if exact_match:\n",
    "            exact_match_count+=1\n",
    "\n",
    "    \n",
    "    number = len(sentences)\n",
    "    per_output_accuracy = [ 0.0 for i in range(10)]\n",
    "    exact_match_accuracy = ((1.0*exact_match_count)/number)*100\n",
    "\n",
    "    for i in range(len(per_word_matches)):\n",
    "\n",
    "        per_output_accuracy[i] = ((1.0*per_word_matches[i]) / number) * 100\n",
    "\n",
    "    averaged_1 = sum(per_output_accuracy)/10\n",
    "    averaged_2 = (sum(per_word_matches)/(10*number))*100\n",
    "\n",
    "    return exact_match_accuracy,per_output_accuracy,averaged_1,averaged_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_test_dataset():\n",
    "    ground_truth = []\n",
    "    sentences = []\n",
    "    with open(\"./Assignment4aTestDataset.txt\",'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            nl_date , out_date = line.split(',')\n",
    "            nl_date = nl_date.replace(\"\\'\",\"\").strip()\n",
    "            out_date = out_date.replace(\"\\'\",\"\").strip()\n",
    "\n",
    "            if \"/\" in nl_date:\n",
    "                #number_list = list(nl_date)\n",
    "                #nl_date = \" \".join(number_list)\n",
    "                split_on_slash = nl_date.split(\"/\")\n",
    "                nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "            nl_date = nl_date.lower()\n",
    "\n",
    "            sentences.append(nl_date)\n",
    "            ground_truth.append(out_date)\n",
    "            \n",
    "    return ground_truth,sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TranslationModel()\n",
    "t.load_state_dict(torch.load('./translation_model_11'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '0', '1', '9', '-', '0', '4', '-', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "output_tokens , attention = translate_sentence('21/04/2019',t.to(device_cpu))\n",
    "print(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.72,\n",
       " [99.45,\n",
       "  97.0,\n",
       "  99.64,\n",
       "  98.72999999999999,\n",
       "  100.0,\n",
       "  99.68,\n",
       "  98.99,\n",
       "  100.0,\n",
       "  98.9,\n",
       "  98.28],\n",
       " 99.067,\n",
       " 99.06700000000001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth,sentences = return_test_dataset()\n",
    "getmetrics(t,sentences,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heatmap(sentence, translation, attention):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(attention, cmap='viridis')\n",
    "\n",
    "    nl_date = sentence.replace(\"\\'\",\"\").strip()\n",
    "    nl_date = nl_date.lower()\n",
    "\n",
    "    if \"/\" in nl_date:\n",
    "        #number_list = list(nl_date)\n",
    "        #nl_date = \" \".join(number_list)\n",
    "        split_on_slash = nl_date.split(\"/\")\n",
    "        nl_date = \" / \".join(split_on_slash)\n",
    "\n",
    "    src = nl_date.split(\" \")\n",
    "    trg = list(translation)\n",
    "\n",
    "    ax.set_xticklabels(src, minor=False, rotation='vertical')\n",
    "    ax.set_yticklabels(trg, minor=False)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    # and the x-ticks on top\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticks(np.arange(attention.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(attention.shape[0]) + 0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.colorbar(heatmap)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens , attention = translate_sentence('Saturday 29 February 2021',t.to(device_cpu))\n",
    "plot_heatmap('Saturday 29 February 2021',''.join(output_tokens),attention.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens , attention = translate_sentence('29 February 2020',t.to(device_cpu))\n",
    "plot_heatmap('9 February 2020',''.join(output_tokens),attention.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(100,64, num_layers= 2 ,batch_first= True ,bidirectional=True)\n",
    "inp = torch.randn((2,8,100))\n",
    "outputs,hidden = rnn(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inq = torch.cat([hidden[-i , : , :] for i in range(4)],dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn(inp)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(10,30)\n",
    "\n",
    "embedding_layer(torch.tensor([[10,2,3],[4,5,6]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcc965cbd87e810c5948a362c404a650a7d80b88f993f5ac595feee5cfd87ac7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
